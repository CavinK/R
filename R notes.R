# R
## 뉴질랜드 오클랜드 대학 ross lhaka, robert clifford gentleman
## 1995년에 개발한 소프트웨어이고 데이터 분석을 위한 통계 및 그래픽스를 지원하는 무료 소프트웨어이다. <- 상용 플랫폼! 많은 기업들이 R로 전환!

# R을 사용해야 하는 이유
## 1. R은 free
## 2. 데이터 분석을 위해서 가장 많이 쓰는 통계 플랫폼이다.
## 3. 복잡한 데이터를 다양한 그래프로 표현할 수가 있다. <- Visualisation
## 4. 분석을 위한 데이터를 쉽게 저장하고 조작할 수 있다. <- 변수 처리 용이(scalar 데이터 타입, 레코드, 배열) <- c(), data.frame()
## 5. 누구든지 유용한 패키지를 생성해서 공유할 수 있고, 새로운 기능에 대한 전달이 빠르다. <- R Developer
## 6. 어떠한 OS에서 설치가 가능하다. 



# 07/23/2018

# 변수 <- 데이터 저장
## - 변수 이름은 알파벳, 숫자, _, .(마침표) 사용한다. (특수문자는 _, . 이것 2개만!)
## - 변수 이름의 첫 글자는 알파벳, .(마침표)로 시작할 수 있다.
## - .(마침표)로 시작할 경우에는 바로 뒤에 숫자를 입력할 수 없다. 

## ex) 변수 이름으로 가능 -> a, i, x2, .y
## cf) 변수 이름으로 불가능 -> 1a, .2, k-j

# 변수에 값 할당연산자(<-, <<-, =)
## 되도록이면 "<-" 이거 쓰는 게 나음!(global variable)
x <- 1 
## R에서는 데이터 타입 따로 표현 안 함!(값에 따라 자동으로 설정)
## "<-": 할당 연산자, 대입 연산(이 변수에 해당 값을 넣겠다는 뜻!)

x
print(x)

y <<- 2 
### "<<-"
y
print(y)

z = 3 
### "="
z
print(z)

x + y + z

# "<-": global variable
## 함수 바깥에 있는 변수에 새로운 값 할당
## 함수 수행하면 변수 내의 값 자체가 바뀜 
## plsql의 bind variable의 기능
sum(x <- c(1,2,3,4,5)) 
### 1차원 배열!(plsql보다 훨씬 쉬움)
### x에 할당된 값이 바뀌었음!
### sum() <- 배열 안에 있는 값들을 합해주는 기능 수행(그룹함수)
x

# "=": local variable
## 함수 안에서만 값이 통용 
sum(y = c(1,2,3,4,5)) 
### y에 배열 입력
### BUT y 변수 내의 값은 안 바뀌었음!(전역변수 vs. 지역변수)
y

sum(f100 = c(1,2,3,4,5)) 
### 함수는 수행됨
### BUT d 변수가 따로 생성되지는 않음 
### local variable
f100

sum(f100 <- c(1,2,3,4,5)) 
### 이 경우에는 변수가 만들어짐!
### global variable
f100

## 함수 안 쓸 때는 "<-", "=" 둘 다 똑같지만, 함수를 제작, 이용하게 될 때는 두 연산자를 구분해서 표현해야 함! 



# 숫자(정수(integer), 실수(numeric))
## 실수(numeric): 부동 소수점 표현 
x <- 2
print(x)
class(x)
### 변수 안에 들어 있는 값의 타입 확인 가능
### numeric: 실수 cf. integer: 정수
### R에서는 숫자를 표현하면 기본적으로 실수로 인식!

### R은 대소문자 구분!
### 숫자 뒤에 L을 집어 넣으면 정수로 저장!(reserved word)
y <- 2L 
print(y)
class(y) 
### integer!

### numeric + integer = numeric
z <- x + y
print(z)
class(z) 

str(z) 
### structure 함수 -> class()와 기능 비슷
### 타입과 값을 같이 표현(num 4)

### boolean function -> 실수인지 아닌지 true/false로 표현!
is.numeric(z) 
is.integer(y)
is.integer(x)



# 문자열 
## ''를 써도 되고, ""를 써도 됨!
s1 <- 'hello'
s1
class(s1)
### character

s2 <- "안녕하세요"
s2
class(s2)

### character면 true, 아니면 false
is.character(s1)
is.character(s2)



# Boolean 형식 <- 진리값 표현 <- TRUE/FALSE 대소문자 구분!
## AND: &
## OR: |

## TRUE & TRUE -> TRUE
## TRUE & FALSE -> FALSE

## TRUE | TRUE -> TRUE
## TRUE | FALSE -> TRUE

# 한 글자만 쓸 때는 해당 글자에 변수가 따로 설정되어 있는 지 먼저 확인!
## T & T
## T & F
## T | T
## T | F

### 변수가 더 우선순위가 더 높음!
T <- TRUE 
T
F <- FALSE
F

class(T) ### logical

### z는 boolean 형식의 변수가 아님 => FALSE
is.logical(T)
is.logical(F)
is.logical(z) 



# NA(Not Available) : 결측값(결측치), 데이터 입력 중 실수로 값이 입력되지 않은 경우 
a <- 100; b <- 90; c <- NA; 
### 한 줄에 여러 변수 입력하고 싶으면 ; 사용!

a
b
c

### NA가 나옴!(결측값이 있어서, 계산할 때 Null처럼 나옴!)
a + b + c 

### 변수 c에 NA가 있는 지의 여부
is.na(c)  
is.na(a)

## cf. NULL: 변수에 초기화되지 않을때 사용, undefined값을 표현 
## NULL은 결측된 게 아니라 그저 변수 안에 값이 안 들어간 것 뿐!
## 변수 선언만 하고 값은 안 넣은 거!
## PLSQL에서는 변수 선언만 하면 자동으로 NULL이 들어가지만, R에서는 NA가 PLSQL의 NULL의 기능을 사용! 
## R에서는 타입을 쓰지 않기 때문에 변수에 NULL이라도 넣어놔야 함!(NA는 아예 진짜 모르겠는 경우)
## NULL <- 변수에 어느 타입의 값이 들어갈 지는 모르겠지만, 변수만 만들어 놓고 싶은 경우 
## 되도록이면 NA로 넣지 말고 NULL로 넣을 것!(NA값이 있을 경우 다른 값으로 대체하는 기능을 가진 함수 사용)
x <- NULL
is.null(x)
is.na(x) 
### logical(0)
### NA와는 다름!

y <- 100
x + y 
### numeric(0)
### NA와는 다름!

z <- NA
z + y 
### NA
### NULL과는 다름!



1 + 2
100 - 99
99 - 100
2 * 3
100 / 2
100 / 3

100 %/% 3 
### 몫만 끄집어냄 
100 %% 3 
### 나머지만 봄(SQL의 mode 함수의 기능)

10 ^ 2 
### 거듭제곱(SQL의 power 함수의 기능)
10 ** 2 
### 위와 똑같음 



# 비교 연산자
10 > 5 
### TRUE
10 < 5 
### FALSE
10 >= 5
10 <= 5
10 == 5 
### == 이렇게 2개 연속해서 써야 함!
10 != 5

## 연결 연산자와 같이 쓸 때는 괄호도 적절하게 사용할 것!
10 > 9 & 10 >= 10 
10 < 9 | 10 >= 10
### 연결 연산자와 같이 사용 



# 숫자(지수표기법) 
1e2 
### 1 * 10^2
5e-1

5e-2
100000 
### 10만 단위는 지수형으로 바뀜 => 숫자를 쭉 나열하는 것보다 지수 형식이 더 편함!
10**5 
### 지수형으로 변환!



# 자료형
## 1. vector: 같은 데이터 타입을 갖는 1차원 배열 
## 2. list: 서로 다른 데이터 타입을 갖는 1차원 배열, 중첩 가능 
## 3. matrix: 같은 데이터 타입을 갖는 2차원 배열 
## 4. array: 같은 데이터 타입을 갖는 3차원 배열 
## 5. factor: 목록, 범주형 데이터 
## 6. data.frame: 서로 다른 데이터 타입을 갖는 컬럼으로 이루어진 2차원 배열 
## 7. table: data.frame 동일한 구조를 갖는데 속도가 빠르다. 



# 1. vector(벡터) <- 1차원 배열!
## - 같은 데이터 타입을 갖는 1차원 배열 구조(R의 기본 데이터 구조)
## - c(): combine value
## - 벡터는 중첩 불가능하다.
## - 벡터는 단일 데이터 타입 가능
## - 데이터 변환 규칙: integer < double < character

x <- c(1,2,3,4,5)
x
mode(x)
class(x)
str(x) 
### 대괄호 <- 벡터의 범위
### 해당 벡터에서 어느 데이터를 뽑으려고 할 때 이 범위 이용!

x <- c(1,2,3,4,'5')
x
mode(x) 
### 하나만 문자형으로 바꿨을 뿐인데, 벡터 자체가 character형으로 바뀜!(integer < double < character)
### 벡터는 단일 데이터 타입만 가능!
class(x)
str(x) 

x <- c(1,2,3.14,4,5)
x
mode(x) 
### numeric으로 바뀜!(integer보다는 double이 우선 순위가 더 높음)
class(x)
str(x)

x <- c(1,2,3,c(4,5))
x 
### 벡터 안에 벡터를 만들면 그냥 풀어버림!
mode(x)
class(x)
str(x)

s1 <- c('서울','대구','광주','부산')
s1
mode(s1)
class(s1)
str(s1) 



# 셀 이름 
x <- c(1,2,3,sum=c(4,5)) 
### sum 함수가 아니라, 이름만 sum인 거!
y <- c(1,2,3,sum(c(4,5)))
x 
### 컬럼명으로 설정됨
y 
### 4번째 위치에 더한 값으로 입력

x <- c('국어'=90, '수학'=95, '영어'=80) 
### 셀 이름과 값을 함께 설정 
### 1차원 배열 안에도 이렇게 셀 이름(컬럼 이름)도 함께 표현 가능!
x

z <- c('과목'=c(80,90,96)) 
### 3개의 값에 하나의 컬럼명 설정 => 과목1, 과목2, 과목3 이런 식으로 표현됨
z

# names(): 벡터의 각 셀에 이름을 설정 
## 셀 이름 변경 
names(z) <- c('국어', '영어', '수학') 
### 컬럼명을 셀의 개수만큼 표현 
z ### 컬럼명이 변경됐음!

# 셀 이름 삭제 <- NULL 사용!
names(z) <- NULL
z ### 컬럼명이 모두 없어짐!

## cf. NA로 할 경우
names(z) <- NA
z 
### 컬럼명이 아예 없어지지 않고, NA로 남음!

y <- c(1,2,3,4,5)
y
names(y) <- c('하나','둘','셋','넷','다섯')
y



# 벡터의 길이 <- length(), NROW()
## 벡터 안에 들어 있는 값의 개수 표현(SQL의 count 함수의 기능 수행)
length(y)
NROW(y) 
### 위와 같은 결과 



# 배열의 원소 조작 <- PLSQL에서는 요소 번호 가지고 조작했음(prior, next ...)
## R은 PLSQL의 nested 배열 타입과 비슷(1번부터 시작)
## 인덱스 번호 or 셀 이름 <- 이 두 가지의 방법을 가지고 요소값을 찾아냄!

# 벡터의 요소 번호를 이용하는 방법
y[1] 
### 벡터 y의 1번 방에 해당하는 값 리턴
y[2]
y[1:3] 
### 1번 방부터 3번 방까지
y[-1,-3] 
### 오류!
y[c(-1,-3)] 
### 1번 방과 3번 방의 요소들 제외 <- minus 부호 사용!(여러 개를 제외시키고 싶을 때는 c() 사용!)

y['하나'] 
### 셀 이름을 가지고도 요소를 볼 수 있음 
y[c('하나','다섯')] 
### 셀 이름으로 검색할 때도 여러 개의 경우에는 c() 사용!

y[-1:-4] 
### 1번 방부터 4번 방까지 쭉 제외 => 5번 방의 값만 나옴!



# 연속되는 값을 표현하는 방법 
x <- 1:100 
### sequence
x <- 1:1e5
x <- c(1:1000) 
### x <- c(시작값:종료값) <- 1씩 자동으로 증가 
x



# sequence: 자동일련번호를 생성 
## seq(시작값, 종료값, 증가분)
seq(1,5,1)
seq(0,1000,5) 
### 0에서부터 1000까지 5씩 증가 

10:1 
### 10에서 1까지 감소(reverse)
seq(10,1,-1) 
### 위와 결과 동일 
seq(10,0,-1)

x <- c(2,4,6,8,10)
x
seq_along(x) 
### 벡터 안에 있는 개수(길이)만큼 sequential하게 일련번호 생성
1:NROW(x) 
### 위와 동일(벡터 개수만큼 sequence 만듬)



# 반복되는 값
rep(1:5, times = 2) 
### 1부터 5까지의 sequence를 2번 반복!
rep(1:5, each = 2) 
### 각각의 값을 2개씩!
rep(1:5, each = 2, times = 2)
rep(1:5, times = 2, each = 2)



# 벡터의 값 수정
x <- c(1:5)
x[2] <- 8 
### 2번 방의 값이 수정
x
x[3:5] <- c(30,40,50)
x[3:5] <- seq(10,12,1)



# 벡터의 값을 추가
x[6] <- 60 
### 6번 방이 추가됨
x
x[8] <- 80 
### 중간에 7번 방은 NA로 처리됨 
x[7] <- 70
x

# append()
append(x,90,after=8) 
### 8번 방 뒤에다가 90을 추가 BUT x로 검색해보면, 변경사항이 반영은 안 되어 있음!(미리보기만 제공)
x 
x <- append(x,90,after=8) 
### 이제 반영!(변수에 넣어줘야 함!)
x
## before는 없음! after만 가능!



# 벡터 연산 
x <- c(1:5)
x + 10 
### 각각의 요소의 값이 다 10씩 더해짐(R의 가장 큰 장점!)
x * 10
## 위 연산 결과를 반영하려면, 변수에 넣어줘야 함!



# 배열 변수 비교
x <- c(1,2,3)
y <- c(1,2,3)
x == y
z <- c(1,2,4)
x == z

## identical() <- 다 맞으면 TRUE, 하나라도 틀리면 FALSE
identical(x,y) 
identical(x,z)

w <- c(1:5)

x == w ## 두 벡터의 length가 다르다는 메시지가 뜸
identical(x,w) 
### FALSE

x <- c(1,2,3,4)
y <- c(1,2,3,4,4)

x == y 
### 5번째 원소에 대해 FALSE가 뜸(x에 5번째 요소가 없기 때문)
identical(x,y) 
### 두 벡터의 값이 동일한 지 판단 => 5번째 요소가 안 맞음 => FALSE!
setequal(x,y) 
### 두 벡터의 같은 집합인지 판단(중복값이 있으면 같은 집합으로 판단!) => TRUE!



# 집합 
x <- c(1,2,3,4)
y <- c(1,4,6)
union(x,y) ### 합집합 => 중복 제거!
intersect(x,y) ### 교집합 
setdiff(x,y) ### 차집합
'''
It is worth pointing out that intersect and setdiff will discard any duplicated values in the arguments. 
Whereas %in% will keep duplicates. So if we had duplicated values we will get different results. 
For example, indroducing a duplicated element a in vector x:
'''
### Keeps duplicated element x(intersect)
x[x %in% intersect(x, y)]
### Keeps duplicated element x(setdiff)
x[!x %in% y]



# %in% 연산자 
1 %in% x 
### x 변수에 1이 있으면 TRUE, 아니면 FALSE
5 %in% x

x <- c('b','a','d','a',NA)
x

'a' %in% x 
### a가 x에 있는 지의 여부는 알 수 있지만, 어느 위치에 있는 지는 알 수 없음

x == 'a' 
### a를 x의 각 요소와 비교 

x[x == 'a'] 
### NA도 리턴됨!
### 조건에 해당하는 요소번호 찾기 



# which() <- 해당값이 어느 위치에 있는 지 파악 
which('a' == x) 
### 해당값이 어느 벡터의 몇 번째에 위치해 있는 지 알 수 있음!
x[which('a' == x)] 
### 바로 위에서 구한 요소 번호를 x[]의 방 번호로 이용!

is.na(x) 
### NA가 있으면 TRUE
which(NA == x) 
### 확인 불가!(NA의 위치는 파악 불가능!)
which(is.na(x)) 
### 이걸로 NA의 위치를 파악해야 함 

x[which('a' == x)] 
x[which('a' == x)] <- 'aa'
x ### a 값을 가진 방만 따로 검색해서 이를 aa로 바꿈!



x <- c(1:5) 
### integer 형식
y <- c(1,2,3,4,5) 
### numeric 형식
setequal(x,y) 
### TRUE
identical(x,y) 
### FALSE(type이 다르기 때문!)
x
y
str(x)
str(y)
y <- as.integer(y) 
### 형변환 함수(numeric => integer) <- SQL의 to_number()
identical(x,y) 
### 이제 TRUE!



# help(), ? 기능 <- 메소드의 인자값으로 뭘 넣어야 할 지 모를 때
help(identical)
?identical



# 2. List형 데이터
## - 서로 "다른" 데이터 타입을 갖는 벡터들을 저장하거나 또다른 리스트 저장가능한 구조이다. 
## - list(키 = 값, 키 = 값)
x <- list(name = '홍길동', addr = '서울시', pn = '010-1111-1234') 
### 문자, 숫자 둘 다 가능
x
str(x)
class(x)
mode(x)
x$name 
### x$키이름
x$addr
x$pn

x[1]
x[[1]] 
### Console에 "$키이름" 부분이 사라지고, 그저 값만 리턴됨!
x[1:3]

## list 요소 추가 
x$sal <- 10000 
### x$새로운키 <- 값 
x

## list 요소 제거
x$sal <- NULL
x

## list 요소 수정
x$pn <- '010-1234-1004'
x

## list 중첩 
y <- list(a=list(val=c(1,2,3)),b=list(val=c(1,2,3,4))) 
### 2개 이상의 리스트들이 하나의 리스트에 들어감 
### data.frame을 쓰면 되니까 굳이 이렇게 쓸 필요는 없음!
y
y$a
y$b





##################################################################################################
##################################################################################################
##################################################################################################





# 07/24/2018
# 3. 행렬 <- 신경망과 관련(Python)
## - 벡터처럼 한가지 유형의 스칼라 값만 저장 
## - matrix 함수를 이용해서 행렬을 생성 
## - 행과 열을 지정(nrow, ncol)

x <- c(1:9) ### 1차원 배열
x <- matrix(c(1:9), nrow=3) ### nrow: 행의 수(#nrow = 3) <- 보편적으로는 행과 열을 같이 생각해서 만듬!
x
x <- matrix(c(1:9), ncol=3) ### ncol: 열의 수(#ncol = 3) 
x
x <- matrix(c(1:9), nrow=3, ncol=3)
x <- matrix(c(1:9), ncol=1) ### 한 행짜리의 열(벡터)
x

nrow(x) ### 행의 수(숫자 타입 리턴!!!)
ncol(x) ### 열의 수
dim(x) ### 행, 열의 수(벡터)
x <- matrix(c(1:9), nrow=3, byrow = T) ### 행부터 값을 채움
x <- matrix(c(1:9), nrow=3, byrow = F) ### 열부터 값을 채움(Default)
x

x <- matrix(c(1,2,3,4), nrow=2, byrow=TRUE, 
            dimnames=list(c('row1', 'row2'), c('col1', 'col2'))) ### 행과 열의 이름 지정(dimnames=list) <- 리스트형으로 지정!

x <- matrix(c(1:9), ncol = 3)
x
dimnames(x) = list(c('row1', 'row2', 'row3'), c('col1', 'col2', 'col3')) ### Matrix부터 만들고 행과 열의 이름을 따로 지정!
                                                                         ### 리스트 안에 벡터로 표현!
x

rownames(x) ### 행의 이름만 확인 및 "수정" <- 벡터 타입!!!
colnames(x)[1] <- 'col0' ### 열의 이름 수정
rownames(x) <- c('r1', 'r2', 'r3') ### 벡터 길이 맞춰줘야 함!
x

cells <- c(1:9)
rname <- c('r1', 'r2', 'r3')
cname <- c('c1', 'c2', 'c3')
x <- matrix(cells, nrow=3, byrow = T, dimnames = list(rname, cname)) ### 따로 떨어져 있는 변수를 조합해서 matrix 생성 
x
(x <- matrix(cells, nrow=3, byrow = T, dimnames = list(rname, cname))) ### 크게 한 번 괄호를 열고 닫으면, 곧바로 변수 내용 확인 가능!

class(x) ### 벡터와 리스트에서는 class와 mode가 같았음
         ### Matrix에서는 자료형 리턴
mode(x) ### mode()에서는 자료 안에 들어간 데이터의 타입 확인 가능

## 행렬이름[행인덱스,열인덱스]
x[1,1] ### 1행 1열의 값 리턴
x[2,1]
x[3,2]
x[1,] ### 1행만 추출
x[,2] ### <- 벡터 타입!!!(콘솔에 가로로 리턴됨)
x[,-2] ### 2열 제외
x[1,-2]
x[1,2:3]
x[c(1,3),c(1,2)] ### 1행과 3행 따로 추출 <- c() 이용!
x['r1',] ### row 이름 가지고도 가능!
x[,'c2']

x[1,1] <- 10; x ### 원소값 수정



# 행렬의 연산 
x <- matrix(c(1:4), ncol=2)
y <- matrix(seq(2,8,by=2), ncol=2)

x + 10
x - 10
10 - x
x / 2
x + x
x - x
x / x
x * x ### 그냥 원소들끼리 곱함
x %*% x ### 행렬 곱
x %*% y

t(x) ### 전치행렬(행과 열의 위치를 바꾼다) ex. 1행 2열 <-> 2행 1열 => 신경망!
solve(x) ### 역행렬
x %*% solve(x) ### 단위행렬(I)

x <- matrix(c(1:6), ncol=3)
x
dim(x)
dim(t(x)) ### 행렬의 모양을 바꾸는 작업!
dim(x) <- c(3,2) ### 이런 식으로도 바꿀 수 있음!!(c() 이용)

## 행렬 병합 
x <- matrix(c(1:9), nrow=3)
y <- matrix(c(1:9), nrow=3)

cbind(x,y) ### 열을 기준으로 합침(가로로 쭉 늘임)
rbind(x,y) ### 행으로 합쳐줌(세로로 쭉 늘임)



# 4. array(배열)
## dim(행, 열, 면)
## - 같은 데이터 타입을 갖는 "3차원" 배열구조 
## - matrix: 2차원 행렬, array 3차원 행렬 <- array를 2차원으로 만들면, 행렬이 됨 
## - array 함수를 이용해서 배열생성 

## 다차원 배열 => 서로 다른 타입의 데이터를 조작!

x <- array(c(1:6), dim=c(2,3)) ### 행렬과 같음
x <- array(c(1:24), dim=c(2,3,4)) ### 4개의 면을 만듬 => 2x3 행렬을 4개 생성!

x[1,1,] ### 각 면의 1행 1열 값만 추출 => 벡터 타입!
x[1,,] ### 1행의 4면만 뽑아냄 
x[,,4]

dimnames(x)
dimnames(x) <- list(c('r1', 'r2'), c('c1', 'c2', 'c3')) ### Matrix와 같음!
x
rownames(x)
colnames(x)

class(x) ### array
mode(x) ### array에 있는 데이터의 타입(numeric)
str(x) ### 종합 
is.matrix(x)
is.array(x)



# 5. factor(팩터) <- 미리 레벨(범주)을 만들어서 벡터의 값 관리!
## - 범주형: 데이터를 미리 정해진 유형으로 분류 ex. job_id, department_id from employees => 이를 변수로 표현!
## - level: (A, B, C, D, E), ('좋음', '보통', '나쁨')
## - 종류: 순서형(ordinal), 명목형(nominal)

## - 순서형(ordinal): 데이터간 순서를 둘 수 있는 경우(ex. A, B, C, D)
## - 명목형(nominal): 데이터간 크기 비교가 불가능한 경우(ex. 남녀) <- default

## 중복 제거!(고유 값으로 추출)

x <- factor('좋음', c('좋음', '보통', '나쁨')) ; x
### factor(값, c(레벨))
x <- factor('아주 좋음', c('좋음', '보통', '나쁨')) ; x
### 레벨 안에 없는 값 넣으면 오류 나옴!(정해진 유형 대로 데이터를 처리해야 할 때만 사용!)
str(x)
class(x)
mode(x) ### 레벨을 character 형식으로 적었는 데도, numeric으로 나옴!

y <- factor('좋음', c('좋음', '보통', '나쁨'), ordered = TRUE) ### ordinal로 만듬!(순서 확인!)
y
str(y) ### 크기: level의 순서!
class(y) ### "ordered" "factor"
mode(y)

nlevels(y) ### 레벨의 개수 => number 타입!!!
levels(y) ### 레벨의 목록 => 벡터 타입!!! 
levels(y)[1]
levels(y)[2]
levels(y)[3]

## 레벨 목록 변경
levels(y) <- c('good', 'normal', 'bad') ; y

is.factor(y)
is.factor(x)
is.ordered(y)
is.ordered(x)

gender <- factor(c("male", "male", "female"), c("male", "female")) ; gender ### nominal!
x <- ordered(c('a','b'), c('a','b','c')) ; x ### ordinal! <- ordered() 사용!
is.ordered(x)
is.factor(x)

## levels = c() 사용
x <- factor(c('large','medium','small','small','large','medium'), levels = c('small','medium','large')) ; x
x <- ordered(c('large','medium','small','small','large','medium'), levels = c('small','medium','large')) ; x

x <- append(x, 'tiny', after = 6) ; x ### level을 문자로 작성했어도, 내부적으로는 numeric으로 가지고 있음!
                                      ### append()를 이용해서 불법 데이터를 추가하면, 나머지는 numeric이 되고, 추가된 데이터만 문자형으로 남음!

## 범주형 => 데이터를 추가하는 게 까다로움

## 해결책: as.vector()를 이용해서 형 변환! => append()를 이용해서 추가한 다음에 as.factor()로 다시 factor로 변환!
x <- as.vector(x) ; x ### 위의 append()를 이용하여 추가 가능(본래의 데이터에는 영향을 주지 않음!)
x <- as.factor(x) ; x ### factor로 형 변환 => level에 자동적으로 tiny가 추가됨!

## level의 순서 변경
x
x <- as.vector(x)
x <- factor(x, c('tiny', 'small', 'medium', 'large')) ; x ### level 순서 변경!(as.vector()로 형 변환 한 다음, 순서 변경!)
                                                          ### factor(벡터명, c(레벨))
x <- as.ordered(x) ; x ### nominal을 ordinal로 바꿈 



# 6. data frame(데이터프레임)
## - 각기 다른 데이터 타입을 갖는 컬럼으로 이루어진 2차원 테이블 구조(DB의 TABLE과 유사하다)
## - data.frame() 함수를 이용해서 각 컬럼, 행을 구성한다.

df <- data.frame(x=c(1,2,3,4,5), y=c(6,7,8,9,10)) ; df
mode(df) ### list형으로 되어 있음! => 서로 다른 데이터 유형의 값들을 모아놓아야 하기 때문! 
class(df)
str(df) ### obs: row의 수 // variables: column의 수 

df$x ### 해당 컬럼만 확인
df$y

df <- data.frame(name = c('scott', 'harden', 'curry'), sql = c(90, 80, 70), plsql = c(70, 80, 90)) ; df
str(df) ### name 컬럼이 factor형으로 되어 있음! => 문자형으로 구성된 컬럼은 factor형으로 자동 설정됨 => 불편함!
df <- data.frame(name = c('scott', 'harden', 'curry'), sql = c(90, 80, 70), plsql = c(70, 80, 90), stringsAsFactors = FALSE) ; df 
### stringsAsFactors = FALSE: 문자형으로 구성된 컬럼을 그냥 문자형으로 놔두라는 뜻!
str(df) ### chr형으로 바뀜! 

## 값을 수정
df[1,1] ### 특정 값 추출
df[1,1] <- 'james' ; df ### 해당 값 변경

## 특정 컬럼을 확인 -> 변수$컬럼명
df$sql ### 벡터 타입!!!
df$name
df$plsql

## 특정 컬럼을 추가
df$R <- c(80, 70, 60) ; df

## 특정 컬럼을 삭제(NULL 사용!)
df$R <- NULL ; df

df[1,]
df[,2]
df[c(1,3),c(1,2)] 
df[-1,-2]
df[,c('sql','plsql')]
df[,'sql'] ### 벡터 타입!!!(가로로 나열되어서 콘솔에 리턴됨!)
df[,'sql', drop = FALSE] ### drop = FALSE <- 열 형태 유지돼서 리턴!

df$sql[1]
df$sql[2]

x <- data.frame(1:3) ; x
colnames(x) <- c("val")  ### 컬럼 이름 지정
rownames(x) <- c('a','b','c') ### 행 이름 지정
x
colnames(x)
names(x) ### 위의 colnames()와 같음 => 둘 중 편한 거 사용! 
names(x) <- c('col') ; x

d <- data.frame(a=1:3, b=4:6, c=7:9) ; d
names(d) %in% c('b','c') ### 각각의 컬럼명을 비교해서 각각 TRUE/FALSE 리턴!(names() <- 벡터 타입!)
d[,names(d) %in% c('b','c')] ### 특정한 컬럼만 뽑아낼 수 있음! 

## NOT 조건
### 숫자는 -(minus) 부호 사용 
### 문자는 ! 사용 
d[,!names(d) %in% c('b','c')] ### ! <- 해당 컬럼은 제외  
d[,-c('b','c')] ### 오류!(컬럼명을 써서 제외시키고 싶으면 "!" 사용해야함)
d[,-c(2,3)]

## 행 추가 
d[4,] <- c(7,7,7)
d[length(d)+1,] <- c(8,9,10) ; d

## 행 삭제
d <- d[-4,] ; d

x <- data.frame(x=1:1000) ; x
head(x) ### 앞부분의 데이터 
tail(x) ### 뒷부분의 데이터 
tail(x, n=10)
head(x,5)





##################################################################################################
##################################################################################################
##################################################################################################





# 07/25/2018

# 자료형
## 1. vector: 같은 데이터 타입을 갖는 1차원 배열 
## 2. list: 서로 다른 데이터 타입을 갖는 1차원 배열, 중첩 가능 <- list(컬럼명 = 값, 컬럼명 = 값)
## 3. matrix: 같은 데이터 타입을 갖는 2차원 배열 <- matrix(벡터, nrow, ncol, byrow = T/F, dimnames = list(c(행), c(열)))
## 4. array: 같은 데이터 타입을 갖는 3차원 배열 <- array(c(데이터), dim = c(행,열,면)) <- x[,,1]
## 5. factor: 목록, 범주형 데이터 <- factor(c(특정값), c(레벨)) // ordered()
## 6. data.frame: 서로 다른 데이터 타입을 갖는 컬럼으로 이루어진 2차원 배열 <- data.frame(컬럼명1 = c(값), 컬럼명2 = c(값)) <- list를 모아놓은 거! 
## 7. table: data.frame 동일한 구조를 갖는데 속도가 빠르다. 

a <- c(1,2)
b <- list(c('king',100))
c <- matrix(c(1,2))
d <- array(1:12, dim = c(2,2,3))
e <- factor(c('male','female'))
f <- data.frame(x = c(1,2))

class(a) ; class(b) ; class(c) ; class(d) ; class(e) ; class(f) ### 자료형 자체의 구조에 대한 부분(그래도 vector는 numeric이라고 나옴!)
mode(a) ; mode(b) ; mode(c) ; mode(d) ; mode(e) ; mode(f) ### 자료형 내의 데이터 종류!
str(a) ; str(b) ; str(c) ; str(d) ; str(e) ; str(f)

## Boolean 함수 
is.numeric(a)
is.character(a)
is.integer(a)
is.factor(e)
is.matrix(c)
is.array(c) ; is.array(d)
is.data.frame(f)
is.list(b)

## 형 변환 함수
as.numeric(a)
as.array(a)
as.matrix(a)

install.packages('readxl')
library(readxl)
emp <- read.csv("C://data/emp.csv") ### csv파일을 data.frame으로 읽어들이는 함수 
View(emp)
str(emp) ### 컬럼 중에 factor라고 되어 있는 부분은 주의!

emp <- read.csv("C://data/emp.csv", header = FALSE) ### header = FALSE <- 컬럼명이 필드값으로 들어감!
View(emp)
str(emp) ### 전부 factor형으로 바뀌었음!

emp <- read.csv("C://data/emp.csv", header = TRUE, stringsAsFactors = F)
View(emp)
str(emp) ### Factor 타입으로 되어 있는 컬럼들이 chr 타입으로 바뀜(해결!)
         ### 필드값이 없으면 NULL(초기값이 설정되지 않은 거)이 아니라 NA(결측치)로 설정됨!

getwd()
setwd('C://data/') ### 주소를 default 설정

names(emp) ### 컬럼 이름 확인 가능!
emp$EMPLOYEE_ID ### 대소문자 구분! => 벡터 타입!
emp$EMPLOYEE_ID == 100 ### 100이 있는 곳에 TRUE => 이걸 요소 번호 부분([])에 집어넣음!(행 제한 기능!)

## emp[행제한, 보고싶은컬럼]
## emp[보고싶은로우, 열제한]
emp[emp$EMPLOYEE_ID == 100,] ### 이 값이 있는 row 추출 <- select * from emp where employee_id = 100;
emp[emp$EMPLOYEE_ID == 100, c('LAST_NAME','SALARY')] ### select last_name, salary from emp where employee_id = 100;

install.packages('sqldf')
library(sqldf)



# 문자함수 
## 0. paste0(): 문자 합치기

## 1. nchar() : 문자 수를 리턴하는 함수(Oracle의 length)
nchar('R Developer')
nchar('R Developer', type = 'chars') ### Default
nchar('R Developer', type = 'bytes') ### 영문자는 글자 수마다 1 byte씩 계산 => 11 bytes

nchar('빅데이터')
nchar('빅데이터', type = 'chars')
nchar('빅데이터', type = 'bytes') ### 한국어는 한 글자가 2 bytes씩! 

## 2. strsplit(): 부분문자로 분리하는 함수 
strsplit('R Developer') ### 오류!(default 설정 안 됨!)
x <- strsplit('R Developer', split = character(0)) ### 스펠링마다 분리시킴!
strsplit('R Developer', split = character(3)) ### 변화 없음! 
strsplit('R Developer', split = " ") ### 공백을 기준으로 split
strsplit('R,Developer', split = ",") ### ,를 기준으로 split

str(x) ### 벡터가 아님! 리스트로 나옴!
unlist(x) ### 리스트 타입을 벡터 타입으로 바꿔줌! 
str(unlist(x))

## 3. toupper(): 대문자로 바꿔줌 
toupper('r developer')

## 3-1. toTitleCase(), str_to_title(): 첫 글자만 대문자로 바꿔줌 
library(tools)
toTitleCase(r)
library(stringr)
str_to_title(r)

## 4. tolower(): 소문자로 바꿔줌
tolower('R DEVELOPER')

## 5. substr(): 문자열 추출(Oracle SQL과 기능이 같음! 기준점(1) 역시 못 바꿈!) => 문자 리턴! 
substr('R Developer',1,1)
substr('R Developer',1,3)

## 6. sub(): 첫번째 일치하는 문자만 바꾸는 함수
### sub(원본글자, 새로운글자, 문장)
sub('R', 'Python', 'R Programmer R Developer')
sub('R Programmer', 'Python Coder', 'R Programmer R Developer')

## 7. gsub(): 일치하는 "모든" 문자를 대체하는 함수
### gsub(원본글자, 새로운글자, 문장)
gsub('R', 'Python', 'R Programmer R Developer')
gsub('[0-2]','*','120304') ### 문장패턴을 찾을 때 유용하게 쓰임! 



# 숫자함수 
## 1. round()
round(45.926)
round(45.926,1) ### 소수점 첫째 자리까지! 
round(45.926,2)
round(45.926,-1) ### 10의 자리까지 반올림(기존의 Oracle SQL과 비슷!)
round(45.926,-2) ### 없으면 0 

## 2. trunc()
### 무조건 소수점을 버리는 작업 수행!(소수점 몇 째 자리까지 버릴 건지는 임의로 설정할 수 없음!)
### %%의 기능과 비슷(몫 버리고 나머지만 취함)
trunc(45.926)
trunc(45.926,1)
trunc(45.926,2) ### trunc()는 2번째 인자의 숫자가 의미 없음! 

## 3. signif()
### 위치값은 기준값! <- 사용에 유의! 
signif(45.926,1) ### 올림!(1을 기준으로 해서 뒤에 있는 것으로부터 반올림!)
signif(45.926,2) ### 소수점 "1"의 자리에서 반올림

## 4. floor()
### 작거나 같은 정수("버림"의 기능)
### trunc()와의 차이 => -(minus)일 때 달라짐!
floor(45.926)
trunc(-45.926)
floor(-45.926)



# 날짜함수 
## 1. 현재날짜 
Sys.Date() ### 서버의 시간 정보!(대소문자 구분!) <- 날짜까지!
Sys.time() ### 시간과 시간대 포함! 
date() ### 미국식으로 표기됨! 

## 2. as.Date(): 문자날짜를 날짜형으로 변환하는 함수 
### 지역에 종속
as.Date('2018-07-25')
as.Date('2018/07/25')
as.Date('20180725') ### 오류!(표준서식에 맞게 입력해야!)
as.Date('20180725', format = '%Y%m%d') ### format을 두번째 인자값으로 입력해야! 

'''
## 3. format
%Y: 세기를 포함한 년도(4자리)
%y: 세기를 생략한 년도(2자리)

%m: 숫자달
%B: 문자달
%b: abbreviated month

%d: 일
%A: 요일
%a: abbreviated weekday 

%u: 숫자요일 1 - 7 월요일(1)
%w: 숫자요일 0 - 6 일요일(0)

%H: 시
%M: 분
%S: 초

%z: timezone 시간 
%Z: timezone name
'''

as.Date('2018년 1월 2일', format = '%Y년%m월%d일') ### 한국어로 표현할 때는, 꼭 format에 한국어를 기입할 것!

## Console에 리턴되는 Date의 형식을 바꾸는 법 
format(Sys.time(), '%y%m%d %z%Z') ### 날짜 모델 요소 어떻게 쓰는 지 기억할 것! 
format(Sys.time(), '%A %a %u %w')
format(Sys.time(), '%B %d일 %Y년')




##################################################################################################
##################################################################################################
##################################################################################################





# 07/26/2018

## 4. weekdays: 요일을 출력해주는 함수 
### weekdays(날짜타입), '%A'
weekdays(Sys.Date())
weekdays(as.Date('1989년 5월 5일', format = '%Y년%m월%d일'))
format(as.Date('1989년 5월 5일', format = '%Y년%m월%d일'), '%A')

## 5. 날짜 계산 
Sys.Date() + 100 ### 날짜 + 숫자(일) = 날짜
Sys.Date() - 206 ### 날짜 - 숫자 = 날짜
Sys.Date() - as.Date('2014-05-20') ### 날짜 - 날짜 = 숫자(difftime)
as.numeric(Sys.Date() - as.Date('2014-05-20')) ### 위의 값을 numeric으로 변경!
as.Date('2014-05-20') - as.Date('2018-11-03') ### -(minus) 값!
Sys.Date() + as.Date('2014-05-20') ### 날짜 + 날짜 => 오류!

## 6. difftime 함수: 두 날짜 간의 일수를 표현 
trunc(difftime('2018-11-22', as.Date('2014-05-20')))
trunc(as.numeric(difftime('2018-11-22', as.Date('2014-05-20'))))

## 7. as.difftime 함수: 시간의 차이 
as.difftime('00:09:30') - as.difftime('00:18:20') ### '00:09:30' <- 시분초 구분해서 표현! 
as.numeric(as.difftime('00:18:20') - as.difftime('00:09:30'))

## 8. lubridate 패키지 
### ymb(숫자) <- cf. as.Date(문자)
install.packages('lubridate')
library(lubridate)
library(stringr)
?lubridate
mdy(05051989) ### date 타입으로 리턴! 
ymd_hms("2010-12-13 15:30:30")
ymd_hms(Sys.time())

### 현재 시간 
now() 

### 연도만 따로 떼어놓음 
year(now())

### 월
month(now())
date <- now()
month(date, label = T) ### Levels => factor 타입! 
month(date, label = F) ### (default) => numeric 타입! 
format(Sys.time(), '%m')

### 일
day(now())
format(Sys.time(), '%d')

### 요일
wday(now()) ### 숫자 값으로 뽑아짐! %u와 다름!
format(Sys.time(), '%A')
format(Sys.time(), '%u')
wday(now(), week_start = 1) ### format의 %u와 같게!(월요일 기준) 
wday(now(), week_start = 7) ### 일요일 기준 <- 그레고리 달력(default)
wday(now(), week_start = 7, label = T) ### Factor type(무슨 요일이 기준으로 되어 있는 지 알 수 있음!)



## 날짜 + 날짜(to_yminterval()의 기능)
years(10) ### 10년(10y 0m 0d 0H 0M 0S)
months(100) ### 100개월(100m 0d 0H 0M 0S) <- to_yminterval('10-00') from SQL
now() + years(10) ### 10년 후
now() + months(100) ### 100개월 후
now() + days(100) ### 100일 후
now() + hours(3) ### 3시간 후
now() + minutes(100) ### 100분 후
now() + seconds(100) ### 100초 후
now() + years(1) + months(1) + days(1) + hours(10) + minutes(20) + seconds(60)

## 시간, 분, 초까지만 표현 
hm('08:00') ### 8시간
hms('02:30:59') ### 초까지
now() + hm('08:00')
now() + hms('02:30:59')



## year() vs. years() <- 구분할 것! 
date <- now()
date
year(date) <- 2017 ### 변수 내에 저장되어 있는 연도를 바꿈! <- 연도를 수정하는 방법! 
date
date - years(1)

month(date) <- 1 ### 월 수를 수정하는 방법 
date

day(date) <- 1 ### 일 수정
date

hour(date) <- 01 ### 시간 변경
minute(date) <- 01 ### 분 수정
second(date) <- 00 ### 초 수정
date ### 0시 00분 00초로 수정하면 아예 안 뜸! 

## 9. 분기
### quarters(날짜)
quarters(Sys.Date()) ### Q3(3분기)



## POSIXct, POSIXt(POSIXlt) 클래스
mode(Sys.Date()) ### numeric
mode(Sys.time()) ### numeric
class(Sys.Date()) ### date
class(Sys.time()) ### POSIXct POSIXt <- POSIX(Portable Operating System Interface) <- UNIX 간 소통 가능한 프로그램 인터페이스의 규약 
                  ### POSIXct(continuous) POSIXt(POSIXlt)(list time)
                  ### r은 날짜 시간 데이터를 처리할 수 있도록 POSIXct, POSIXt(POSIXlt) 클래스를 사용한다. 
Sys.time()
as.numeric(Sys.time())

## as.POSIXlt()
time <- as.POSIXlt(Sys.time())
unlist(time) 
'''
sec: 초
min: 분
hour: 시
mday: 그달의 일
mon: 1월을 0으로 시작
year: 1900년을 0으로 ex. 1900+118 = 2018(year: "118")
wday: 일요일 0 ex. 목요일(wday: "4") <- "%w"
yday: 1월 1일 0
isdst: 서머타임 ex. 0 <- 서머타임을 지정하지 않았다는 뜻 
zone: timezone name
gmtoff: timezone 시(초 단위) <- KST(+9) <- GMT offset
'''

date <- '2018-07-26'
class(as.Date(date, format('%Y-%m-%d'))) ### Date
strptime(date, format='%Y-%m-%d') ### 날짜와 시간대 표시 
class(strptime(date, format='%Y-%m-%d')) ### POSIXct POSIXt



# 중복 제거 <- unique()
unique(emp$JOB_ID)

# 정렬(SORT) <- sort()
## sort 작업하면, NA가 없어짐! 
x <- c(3,2,4,8,6,5,10,NA,1,11,NA,15)
x[which(is.na(x))]

sort(x) ### 자동적으로 NA가 없어짐! 
sort(x, decreasing = FALSE) ### 오름차순
sort(x, decreasing = TRUE) ### 내림차순
sort(x, decreasing = FALSE, na.last = NA) ### NA 출력 안 함
sort(x, decreasing = FALSE, na.last = TRUE) ### NA를 마지막에 출력 
sort(x, decreasing = FALSE, na.last = FALSE) ### NA 처음에 출력 
rev(sort(x)) ### reverse function => 순서 반대로! 

# Order: 정렬의 색인을 반환
## data.frame에서 행 부분을 제한할 때 sort()가 아닌 order()를 씀! 
df[order(df$weight),]
df[order(-df$weight),] ### minus <- 내림차순 
x <- c(3,5,1,4,2)
sort(x)
order(x) ### 처음 변수 선언할 때의 순서 그대로 정렬! 
x <- c(30,50,10,40,20)
sort(x)
order(x) ### Index의 번호 리턴!(30-3, 50-5, 10-1, 40-4, 20-2)
x[order(x)] ### sort()의 결과와 같음! 
x[order(x, decreasing = TRUE, na.last = NA)]
x[order(x, decreasing = FALSE, na.last = NA)]
x[order(x, decreasing = TRUE, na.last = TRUE)]
x[order(x, decreasing = TRUE, na.last = FALSE)]

# doBy: 데이터 프레임에 정렬 
install.packages('doBy')
library(doBy)
??doBy

### orderBy(~정렬컬럼, 데이터프레임[,c(컬럼)]) <- order by 절 in SQL 
orderBy(~SALARY, emp[,c("LAST_NAME", "SALARY")]) ### ~(Default): 오름차순 
orderBy(~-SALARY, emp[,c("LAST_NAME", "SALARY")]) ### ~-: 내림차순
orderBy(~SALARY, emp[,c("LAST_NAME", "SALARY", "DEPARTMENT_ID")])
orderBy(~DEPARTMENT_ID+SALARY, emp[,c("LAST_NAME", "SALARY", "DEPARTMENT_ID")]) ### DEPARTMENT_ID부터 정렬하고, 그 다음 SALARY 정렬! 
orderBy(~+DEPARTMENT_ID+SALARY, emp[,c("LAST_NAME", "SALARY", "DEPARTMENT_ID")])
sqldf('select last_name, salary, department_id from emp order by department_id, salary')
orderBy(~-DEPARTMENT_ID-SALARY, emp[,c("LAST_NAME", "SALARY", "DEPARTMENT_ID")]) ### 내림차순(앞의 두 컬럼에 모두 - 붙이기!)
sqldf('select last_name, salary, department_id from emp order by department_id desc, salary desc')





##################################################################################################
##################################################################################################
##################################################################################################





# 07/27/2018

# 그룹함수 
x <- c(100,90,80,70)

sum(x) ### 합
mean(x) ### 평균
var(x) ### 분산
sd(x) ### 표준편차

max(x) ### 최대값
min(x) ### 최소값
length(x) ### 원소의 개수
NROW(x) ### length()와 같음 <- "count()" in SQL

x <- c(100,90,80,70,NA)
sum(x) ### 결측치 들어 있으면 결과값 리턴되지 않음! 
sum(x, na.rm = T) ### na.rm = T <- NA를 지우고 수행하라는 뜻 <- sum(na.omit(x)) 이렇게 써도 됨! 
sum(x, na.rm = F) ### Default
mean(x, na.rm = T)
var(x, na.rm = T) 
sd(x, na.rm = T)
max(x, na.rm = T) 
min(x, na.rm = T) 
length(x) ### 이건 NA가 포함되어도 반영되서 나옴!(결측치도 개수에 계산)
NROW(x)

length(na.omit(x)) ### NA를 제외하고 개수 카운트! 

sqldf('select sum(salary), avg(salary) from emp;')
sqldf('select sum(salary), avg(salary) from emp group by department_id;') ### 그룹 분할한 다음 집계값을 구함! 
sqldf('select sum(salary), avg(nvl(salary,0)) from emp group by department_id;')

mean(x, na.rm = T) ### NA가 제외된 평균 => SQL의 nvl() 함수처럼, NA를 0으로 바꾸고 계산해야 함!!!
x[which(is.na(x))] <- 0
mean(x, na.rm = T) ### 값이 달라졌음! (실제 개수를 나눠서 평균 계산)



# aggregate 함수
## group by 집계 함수 in SQL 
## 데이터를 분할하고 각 "그룹"으로 묶은 후 그룹 함수를 적용한다.
## aggregate(계산될컬럼 ~ 분할해야할 기준컬럼1 + 기준컬럼2, 데이터, 함수)
## aggregate(salary     ~ department_id + JOB_ID          , 데이터, 함수)
aggregate(SALARY ~ JOB_ID, emp, sum)
sqldf('select job_id, sum(salary) from emp group by job_id')
aggregate(SALARY ~ JOB_ID, emp, mean)
aggregate(SALARY ~ JOB_ID, emp, max)
aggregate(SALARY ~ JOB_ID, emp, min)



# apply 함수
## - 행렬, 배열, 데이터프레임에 함수를 적용한 결과를 벡터, 리스트, 배열 형태로 리턴한다. cf) 단일 열(vector)을 집계하는 건 sum()을 써도 됨! 
## - 행렬에서 행이나 열의 방향으로 함수를 적용 

## apply(x, MARGIN, FUNC)
### x: 행렬, 배열, 데이터프레임
### MARGIN: 함수를 적용할때 방향을 지정
###         1 -> 행 방향 // 2 -> 열 방향 // c(1,2) -> 행과 열의 방향 
### FUN: 적용할 함수(sum, mean, var, sd, max, min)

### Matrix에 적용 
m <- matrix(1:4, ncol=2) ; m
dim(m) ### 2x2 행렬 
apply(m,1,sum) ### matrix를 행 방향으로 sum => 벡터 타입으로 리턴! 
apply(m,2,sum) ### 열 방향

apply(a,1,sum) ### 행끼리의 합
apply(a,2,sum) ### 열끼리의 합
apply(a,3,sum) ### 면끼리의 합(array)

### Data Frame에 적용 
df <- data.frame(name = c('king', 'smith', 'jane'), sql = c(90, NA, 70), python = c(75, 90, NA)) ; df ### 첫번째 열은 char 타입이라서 계산할 수 없음! => 행 제한!(df[,2])
apply(df[,2],2,sum) ### apply()는 행렬, 배열, 데이터프레임의 모양으로 되어 있어야 함! => 벡터 형태면 그냥 sum() 써도 됨! 
apply(df[,c(2,3)],1,sum) ### 2열에서 3열까지 horizontal sum! => 벡터 타입으로 리턴! 
apply(df[,c(2,3)],1,sum, na.rm = T) ### apply()에도 "na.rm = T" 적용 가능! 

apply(df[,c(2,3)],2,sum)
apply(df[,c(2,3)],2,sum, na.rm = T) ### 컬럼명도 같이 나옴 => 리스트 타입! 



## rowSums(): 배열, 행렬, 데이터프레임의 행의 합 (벡터 X)
## rowMeans(): 배열, 행렬, 데이터프레임의 행의 평균 
rowSums(df[,2:3], na.rm = T) ### apply()의 MARGIN 1과 같음! 
rowMeans(df[,2:3], na.rm = T)
rowMeans(df[,c(2,3)], na.rm = T) ### 위와 같음(따로 떨어져 있는 열을 집계할 때는 c() 사용!)

## colSums(): 배열, 행렬, 데이터프레임의 열의 합 (벡터 X)
## colMeans(): 배열, 행렬, 데이터프레임의 열의 평균 
colSums(df[,2:3], na.rm = T) ### apply()의 MARGIN 2와 같음! 
colMeans(df[,2:3], na.rm = T)



# lapply()
## - 벡터, 리스트, 데이터프레임에 함수를 적용하고 그 결과를 리스트로 리턴하는 함수 
## - 리스트: 서로 다른 데이터 타입에 값을 저장하는 자료형이다. 
x <- list(a = 1:3, b = 4:6) ; x ### x는 리스트이지만, 그 안에 a만 뽑아냈으면 그건 벡터! 
str(x)
median(x$a) ### x$a <- 벡터! 
median(x$b)
lapply(x,median) ### 위의 두 작업(median(x$a), median(x$b))을 한 번에 끝냄! 
sapply(x,median) ### lapply()의 리턴값을 간략화한 거! 

lapply(df[,2:3],mean,na.rm=T) ### 리스트 타입
apply(df[,2:3],2,mean,na.rm=T) ### 데이터프레임 타입 
colMeans(df[,2:3], na.rm = T) ### 이 셋 중에 맘에 드는 거 골라 쓰면 됨! => 자료형에 따라 apply 함수 맞춰줘야! 



## 리스트를 데이터프레임으로 바꾸는 방법(vector -> matrix -> data.frame)
### 1. 리스트를 벡터로 바꿈(unlist())
### 2. 벡터를 매트릭스로 바꿈(matrix())
### 3. 매트릭스를 데이터프레임으로 바꿈(as.data.frame())
### 4. 컬럼의 이름을 바꿔줌(names() <- c())
lapply(df[,2:3],mean,na.rm=T) ### 리스트 형태 
unlist(lapply(df[,2:3],mean,na.rm=T)) ### unlist() => 벡터 타입으로 바뀜! (데이터프레임처럼 생겼지만 실제 모양은 벡터!)
matrix(unlist(lapply(df[,2:3],mean,na.rm=T)), ncol=2, byrow=T)  
as.data.frame(matrix(unlist(lapply(df[,2:3],mean,na.rm=T)), ncol=2, byrow=T))
names(x) <- c('sql', 'python') ; x

x <- as.data.frame(matrix(unlist(lapply(df[,2:3],mean,na.rm=T)), ncol=2, byrow=T)) ### data frame -> 다른 타입의 컬럼으로 구성 
str(x)
class(x)
mode(x) ### 안에는 리스트 형태로 되어 있음! 



# sapply()
## - 벡터, 리스트, 데이터프레임에 함수를 적용하고 그 결과를 벡터로 리턴하는 함수 
x <- sapply(df[,2:3], mean, na.rm = T) ; x
str(x)
class(x)
mode(x)

x <- as.data.frame(matrix(sapply(df[,2:3], mean, na.rm = T), ncol=2, byrow=T))
names(x) <- c('sql', 'python') ; x

t <- as.data.frame(t(as.data.frame(x)))
str(t)
class(t)
mode(t)



# tapply()
## aggregate()와 비슷한 거! 
## - 벡터, 데이터프레임에 저장된 데이터를 주어진 기준에 따라 그룹으로 묶은 뒤 그룹함수를 적용하고 그 결과를 array 형식으로 리턴하는 함수 
tapply(emp$SALARY, emp$DEPARTMENT_ID, sum) ### tapply(): 가로로 나열(array 모양)
aggregate(SALARY ~ DEPARTMENT_ID, emp, sum) ### aggregate(): 세로로 나열 

tapply(emp$SALARY, c(emp$DEPARTMENT_ID, emp$JOB_ID), sum) ### BUT tapply()는 combine이 안 됨! 
tapply(emp$SALARY, list(emp$DEPARTMENT_ID, emp$JOB_ID), sum) ### c() 대신 list()를 사용! => NA들이 나오는 게 지저분함! 
tapply(emp$SALARY, list(emp$DEPARTMENT_ID, emp$JOB_ID), sum, default = 0) ### NA 대신 0를 display 시킴! 





##################################################################################################
##################################################################################################
##################################################################################################





# 07/30/2018

ls() ### 메모리에 선언되어 있는 변수명 => 예약어가 변수로 설정되어 있는 지 확인! 
rm(y) ### 변수명 삭제 
rm(list=ls()) ### 모두 삭제 => 이거 수행하고 다시 ls() 해보면, "character(0)"라고 뜸! 



# 제어문 <- if 구조
## 조건의 흐름을 제어하는 방법



## 1. if문: 조건에 따라 서로 다른 코드를 수행하도록 하는 문장 
### R에서는 {}로 구분! 
'''
if (조건) {
              조건이 참일 때 수행하는 문장
} else {
              조건이 거짓일 때 수행하는 문장 
          }
'''

## ex. 
if(1<2){
  print("2가 1보다 크다")
}else{
  print("1은 2보다 작다")
}
ifelse(x%%2 == 0, "2의 배수", "2의 배수가 아니다") ### print() 함수를 따로 쓸 필요는 없음! (ifelse() 함수가 자동으로 리턴!)

### sub if문도 가능! (else절에 또다른 if문을 작성)



## 2. ifelse() 함수 <- if문을 함수로 요약 
### ifelse(조건, 참, 거짓)



## else에 if문 중첩 <- PLSQL처럼 else if는 못 씀! 
x <- 3
if (x==1) {'남은 기간 최선을 다하자'
} else {if(x==2){'내년에도 다른 학원 또 다니지 뭐'
  } else { if(x==3) {'그냥 사는 거지 뭐'}}
}



## 3. switch문
### switch(위치변수, 실행문1, 실행문2, ...) <- 변수값(1,2,3)에 따라 조건에 맞는 실행문을 수행한다. 
### 위의 중첩 if문(else if문)을 간소화! 
x <- 3
switch(x,'남은 기간 최선을 다하자','행복하자','건강하게 살자') ### x 변수에 위치값을 갖고 있으면 됨 

### 위치값 따로 지정! 
### switch(위치변수, 위치값 = 값, else값) <- 위치변수에는 무조건 단일값만 들어갈 수 있음! 
x <- '강'
switch(x, '산' = '한라산 가고 싶다', '바다' = '함덕해수욕장 가고 싶다', '그냥 방콕하세요')



# 반복문 
## 1. for문
'''
for(변수 in 데이터변수) {
                         반복수행할 문장
                        }
'''
for(i in 1:10){
                print(i)
}
### i <- 수행해야할 값만큼 i가 수행됨 
### 아래처럼 따로 i <- i+1을 설정할 필요 없음! 

## 2. while문
'''
while(조건문) {
                반복수행할 문장
}
'''
i <- 1
while (i<=10) {
  print(i)
  i <- i+1 ### for문과의 차이점! 
}

## 3. repeat(기본 loop문) <- 무한루프의 우려! => break 명령문을 통해 무한루프 방지! 
### break는 while문이나 for문에서도 사용 가능! 
'''
repeat {
        반복수행할 문장
}
'''
i <- 1
repeat{
  print(i)
  if (i==10) {break}
  i <- i+1
}

x <- 1:5
for (i in x){
  if (i==3){
    break
  }
  print(i)
}

## cf. next: 해당 요소를 skip!(3만 제끼고 나머지 리턴!)
x <- 1:5
for (i in x){
  if (i==3){
    next
  }
  print(i)
}





##################################################################################################
##################################################################################################
##################################################################################################





# 07/31/2018

### PLSQL -> mutating error(함수는 표현식의 일부로 호출되기 때문에, DML 작업을 동시에 하는 경우, error 발생!)
### Python -> 모듈식 개발 패키지(관련성 있는 프로그램들만 모아 놓음 => 관리 편함!)
### 바인드 변수 -> 툴에 종속 // 패키지를 이용하면 global variable을 보다 편리하게 사용 가능! 



# 함수(function)
## - 사용자가 정의하는 함수를 생성할 수 있다. (의도적으로)
## - 자주 반복되어 사용하는 기능을 정의하는 프로그램 
## - 코드 간단해진다. 

### 코드가 어딘가에는 저장되어 있음 => 소스 코드 가지고 있어야 해당 함수를 사용 가능! 
### 기본적으로 제공하는 함수 외에는, 관련성 있는 함수들을 모아놓은 패키지를 library()로 호출해서 사용하는 것! 

'''
함수이름 <- function(){
                        함수 수행해야 할 코드
                        return(반환값) ### optional
}
'''
### 변수 설정하듯이, 함수도 "<-"를 이용해서 만듬! 

Sys.Date()

date1 <- function(){
  return(Sys.Date())
}
date1() ### 함수로 이용 가능! 

date2 <- function(){
  Sys.Date()
}

time <- function(){
  Sys.time()
}

date2()
time()
### return() 없어도 가능! 

hap <- function(x,y){
  res <- x+y ### res: local variable(함수 내에서만 사용되는 변수)
  return(res)
}
hap(1,2)



## 가변인수
### 매개변수의 개수를 가변적으로 만들고 싶을 경우 => "..." <- 변수 이름을 이렇게 설정! 
f <- function(...){
  x <- list(...) ### "..."의 값이 이 곳에 들어옴 
  for (i in x){
    print(i) ### 출력은 벡터 모양!
  }
}
f(1,2,3,4,5)
f('a','b','c','d')
### 매개변수의 개수에 상관없이 함수가 수행됨! 

f <- function(...){
  x <- c(...) ### combine c 써도 상관 없음! 
  for (i in x){
    print(i)  
  }
}
f(1,2,3)



## 중첩함수
### 중첩된 함수는 함수 내부에서 따로 호출! 
f <- function(x,y){
  print(x)
  f2 <- function(y){
    y <- x*y ### y <- local variable
    print(y)
  }
  f2(y) ### 이거 없으면 f2 부분의 실행값을 확인할 수 없음! => 중첩된 함수는 함수 내부에서 따로 호출해야!! 
}
f(10,20)



## 전역변수(global variable)
### 함수에 상관없이 프로그램 전체에서 사용할 수 있는 변수 

## 지역변수(local variable)
### 함수 내에서 정의되고 사용하는 변수 

## 매개변수(parameter variable)
### 함수의 인수에서 받아서 사용하는 변수 

## a. "<-"
x <- 1 ; y <- 2 ; z <- 3 ### global variables
f <- function(x) {
  y <- x*10 ### "<-": local variable처럼 사용, 프로그램 안에서만 쓰이는 변수(global variable에 영향을 주지 않음)
  print(x); print(y); print(z) ### x,z: global variables // y: local variable
}
f(x)
x ; y ; z ### 위의 f(x)의 리턴값과는 별개로 그냥 global variables의 값 리턴! (y값에 주목!)

## b. "<<-"
x <- 1 ; y <- 2 ; z <- 3 
f <- function(x) {
  y <<- x*10 ### "<<-": 아예 새로운 global variable로 대체(단순한 local variable이 아니라, global variable에도 영향을 준다는 뜻!)
  print(x); print(y); print(z) 
}
f(x)
x ; y ; z ### 아까와는 달리, global variable로서의 y값도 바뀜!!! 

## c. "="
x <- 1 ; y <- 2 ; z <- 3 
f <- function(x) {
  y = x*10 ### "=": local variable!  
  print(x); print(y); print(z) 
}
f(x)
x ; y ; z

### 위에 sum() 부분의 global, local variables의 설명 한 번 다시 확인해보고, 비교해볼 것! 
sum(x1 <- c(1,2,3,4,5)) ; x1 ### local, BUT sum() 밖에서도 x1 사용 가능(따로 변수 선언까지 됨!)
sum(y1 <<- c(1,2,3,4,5)) ; y1 ### global
sum(z1 = c(1,2,3,4,5)) ; z1 ### local(sum() 밖에서는 z1 사용 못 함) <- 가장 local스러움! 



# merge(SQL의 join 기능 수행!)
## 두 데이터프레임의 공통된 값을 기준으로 병합한다.
x1 <- data.frame(id = c(100,200,300), sql = c(70,90,80))
y1 <- data.frame(id = c(100,200,500), python = c(80,70,60))
rbind(x1,y1) ### 오류!(컬럼명이 다르기 때문)
cbind(x1,y1) ### 이상하게 붙여짐! 

merge(x1,y1) ### 수행되는데, 일치되는 값만 리턴됨 => 두 데이터프레임의 "공통"된 값(id 컬럼을 기반으로 merge!) => 일치되는 값만 나옴! 
             ### => equi join과 같음! (키값이 일치되는 것만 추출)
             ### natural join(join 조건 술어를 R이 자동적으로 설정 => "공통된 값을 기준으로 병합")
merge(x1,y1,all=T) ### 일치되지 않은 값까지 나옴(full outer join)
merge(x1,y1,all.x = T) ### x1에 있는 값(id = 300)만 리턴(일치되지 않은 값 중에서) => left outer join
merge(x1,y1,all.y = T) ### x2에 있는 값(id = 500)만 리턴(일치되지 않은 값 중에서) => right outer join

x1 <- data.frame(id = c(100,200,300), sql = c(70,90,80))
x2 <- data.frame(id = c(100,200,300), sql = c(80,70,60))
x3 <- data.frame(no = c(100,200,500), python = c(80,60,70))

merge(x1,x3,all=T) ### 동일한 컬럼 이름이 없음! 
merge(x1,x3,by.x = 'id',by.y = 'no',all = T) ### x1의 'id'와 x3의 'no'를 동일한 컬럼으로 간주! 
                                             ### join 대상 컬럼 이름을 따로 지정 => SQL의 join on절과 비슷한 기능!(cf. natural join)

x4 <- merge(x1,x3,by.x = 'id',by.y = 'no',all = T) ; x4 ### 컬럼 이름이 id로 되어 있음!(첫번째 DF를 중심으로!)

merge(x4,x2,by.x = 'id',by.y='id', all=T) ### SQL 값들이 서로 다르기 때문에, 별로의 컬럼을 따로 만듬! 



dept <- read.csv("C://data/dept.csv", header = TRUE, stringsAsFactors = F)
View(dept)

w <- merge(emp,dept,by="DEPARTMENT_ID") ### "by = 기준컬럼" <- join using절 쓰는 것처럼 사용! 
head(w)
v <- sqldf('select * from emp e join dept d where e.department_id = d.department_id')
head(v,5)

merge(emp,dept,by="DEPARTMENT_ID")[,c("LAST_NAME","DEPARTMENT_NAME")] ### joined table에서 특정 컬럼만 확인
v[,c("LAST_NAME","LOCATION_ID")]





##################################################################################################
##################################################################################################
##################################################################################################





# 08/01/2018

# subset()
## 조건에 만족하는 데이터를 선택(필터링)
## 자동적으로 NA를 처리함! 
emp[emp$DEPARTMENT_ID == 20,]
subset(emp,DEPARTMENT_ID == 20) ### 바로 위의 코드와 같은 행 제한 기능 수행! => NA 자동으로 처리! 

emp[,c("LAST_NAME","SALARY","DEPARTMENT_ID")]
subset(emp, select = c(LAST_NAME, SALARY, DEPARTMENT_ID)) ### select = c() <- 컬럼 추출 가능!(""는 제외할 것!)

names(emp) ### DF에 포함된 컬럼명 확인 가능
emp[,names(emp) %in% c("LAST_NAME","SALARY","DEPARTMENT_ID")] ### 위와 같음 
emp[,!names(emp) %in% c("LAST_NAME","SALARY","DEPARTMENT_ID")] ### 해당 컬럼을 제외한 컬럼들 확인 가능(! 사용)
subset(emp, select = -c(LAST_NAME, SALARY, DEPARTMENT_ID)) ### 해당 컬럼을 제외한 컬럼들 확인 가능(- 사용)

### subset(대상데이터, 행제한, select = c(열추출))
subset(emp, SALARY >= 10000, select = -c(LAST_NAME, SALARY, DEPARTMENT_ID)) ### 행 제한
emp[emp$SALARY >= 10000,!names(emp) %in% c("LAST_NAME","SALARY","DEPARTMENT_ID")]



# sqldf() 메소드 
## SQL을 이용해서 데이터를 처리한다. 
## MySQL, SQLlite 기반! 
install.packages('sqldf')
library(sqldf)

sqldf('select * from emp')
sqldf('select * from dept')
sqldf('select * from loc')
sqldf('select job_id from emp')
sqldf('select distinct job_id from emp') ### unique() 기능 
sqldf('select * from emp where department_id = 20') ### where절: 행 제한 // select절: 열 추출 
sqldf('select * from emp limit 10') ### 10개의 튜플만 보여달라는 뜻 <- head() 기능
sqldf('select last_name, salary from emp order by salary desc') ### doBy 패키지의 orderBy() 기능 
sqldf('select last_name as name, salary from emp order by salary desc') ### names() 기능(alias)
sqldf('select count(*) from emp')

length(emp) ### 컬럼의 개수
NROW(emp) ### 튜플의 개수
sum(emp$SALARY)
mean(emp$SALARY)
sd(emp$SALARY)
var(emp$SALARY)
max(emp$SALARY)
min(emp$SALARY)

c(NROW(emp), sum(emp$SALARY), mean(emp$SALARY), sd(emp$SALARY), var(emp$SALARY), max(emp$SALARY), min(emp$SALARY))
sqldf('select count(employee_id), sum(salary), avg(salary), variance(salary), stdev(salary), max(salary), min(salary) from emp')

sqldf('select department_id, sum(salary) from emp group by department_id')
sqldf('select department_id, sum(salary) from emp group by department_id having sum(salary) >= 20000')
sqldf('select department_id, job_id, sum(salary) from emp group by department_id having sum(salary) >= 20000') ### group by절에 job_id가 빠졌는 데도 오류가 안 남! => BUT 결과값이 다름! 
sqldf('select department_id, job_id, sum(salary) from emp group by department_id, job_id having sum(salary) >= 20000')

sqldf('select last_name, upper(last_name), lower(last_name), substr(last_name,1,2), length(last_name), 
      leftstr(last_name,2), rightstr(last_name,2), reverse(last_name)
      from emp') ### leftstr(): 왼쪽 몇 글자만 추출 // rightstr(): 오른쪽 몇 글자 추출 // reverse(): 글자를 반대로 

sqldf('select * from emp where department_id is null') ### SQL의 NULL = R의 NA
sqldf('select * from emp where department_id in (10,20)')
sqldf('select * from emp where salary between 10000 and 20000')

sqldf('select e.last_name, d.department_name
      from emp e, dept d
      where e.department_id = d.department_id') ### Oracle 형식 
sqldf('select e.last_name, d.department_name
      from emp e join dept d
      on e.department_id = d.department_id') ### ANSI 표준 
sqldf('select e.last_name, d.department_name
      from emp e join dept d
      using(department_id)')
sqldf('select e.last_name, d.department_name
      from emp e left outer join dept d
      on e.department_id = d.department_id') 
sqldf('select e.last_name, d.department_name
      from emp e right outer join dept d
      on e.department_id = d.department_id') ### 오류! (right outer join을 제공하지 않음) => 그냥 테이블 이름의 위치만 바꾸면 됨! 
sqldf('select e.last_name, d.department_name
      from emp e full outer join dept d
      on e.department_id = d.department_id') ### 오류! (full outer join을 제공하지 않음)

sqldf('select e.last_name, d.department_name
      from emp e left outer join dept d
      on e.department_id = d.department_id
      union
      select e.last_name, d.department_name
      from dept d left outer join emp e
      on e.department_id = d.department_id') ### union을 사용함으로서 full outer join의 결과를 얻을 수 있음! (중복 제거)

sqldf('select e.last_name, d.department_name
      from emp e left outer join dept d
      on e.department_id = d.department_id
      union all
      select e.last_name, d.department_name
      from dept d left outer join emp e
      on e.department_id = d.department_id') 

sqldf('select e.last_name, d.department_name
      from emp e left outer join dept d
      on e.department_id = d.department_id
      intersect
      select e.last_name, d.department_name
      from dept d left outer join emp e
      on e.department_id = d.department_id') 

sqldf('select e.last_name, d.department_name
      from emp e left outer join dept d
      on e.department_id = d.department_id
      except
      select e.last_name, d.department_name
      from dept d left outer join emp e
      on e.department_id = d.department_id') ### minus <- 오류! 

sqldf('select * from emp
      where salary > (select salary from emp where employee_id = 150)') ### subquery(where절에 select문)도 가능! (Inline View(from절에 select문)도 가능!)

### 날짜 <- 타입 체크가 필요함!(Date 타입으로는 안 되고, char 타입이어야 함!)
emp$HIRE_DATE <- ymd(emp$HIRE_DATE)
sqldf('select * from emp where hire_date > "2002-01-01"') 

sqldf('select 1+2') ### dual 제공 안 함! 





##################################################################################################
##################################################################################################
##################################################################################################





# 08/02/2018

fruits <- read.csv("C://data/fruits_sales.csv",stringsAsFactors = F)
View(fruits)



aggregate(SALARY ~ DEPARTMENT_ID, emp, mean) ### group by절 생각! DEPARTMENT_ID에 NA에 해당되는 데이터 생략됨! 
aggregate(SALARY ~ DEPARTMENT_ID + JOB_ID, emp, mean)

# ddply
## 데이터프레임을 분할하고 함수를 적용한 뒤 데이터프레임으로 결과를 반환하는 함수
install.packages("plyr")
library(plyr)

## ddply(data, 기준컬럼, 함수) 
### data.frame을 입력값으로 받아서 data.frame으로 리턴
ddply(emp, 'DEPARTMENT_ID', summarise, avg_sal = mean(SALARY)) ### NA까지 포함! (avg_sal이라는 별도의 컬럼을 만들어서 data.frame을 구성!)

## summarise: 기준컬럼의 데이터끼리 모은 후 함수에 적용 
### 굳이 rbind()할 필요 없이 자동적으로 NA 반영! 
ddply(emp, c('DEPARTMENT_ID','JOB_ID'), summarise, avg_sal = mean(SALARY))
ddply(emp, 'DEPARTMENT_ID', summarise, avg_sal = mean(SALARY), sum_sal = sum(SALARY)) ### 별도의 열을 계속 만들어서 그룹 함수를 쭉 나열할 수 있음! 
ddply(emp, 'DEPARTMENT_ID', summarise, cn = length(EMPLOYEE_ID), avg_sal = mean(SALARY), sum_sal = sum(SALARY))

## transform: 각 행별(name, year)로 연산을 수행해서 행당값을 출력하는 기능 
ddply(fruits,"name",transform,'s_qty'=sum(qty)) ### 과일의 판매 변동 현황을 파악하는 것이 가능! (s_qty: 지난 4년 간 판매된 해당 과일의 총합)
ddply(fruits,"year",transform,'s_qty'=sum(qty)) ### 연도 별로 정렬! 
ddply(fruits,"name",transform,'s_qty'=sum(qty), pct_qty=(100*qty)/(sum(qty))) ### pct_qty: 총합 대비 해당 과일의 판매 비율 
ddply(fruits,"year",transform,'s_qty'=sum(qty), pct_qty=(100*qty)/(sum(qty))) ### 연도(year)를 기준으로! (해당 "연도"의 판매량 합이 100)



# dplyr
## 필터 기능! 
install.packages('dplyr')
library(dplyr)

emp[emp$DEPARTMENT_ID==20,]
emp %>% filter(DEPARTMENT_ID==20) ### 행 제한 
emp %>% select(SALARY) ### 열 추출 

## filter: 조건을 줘서 필터링하는 함수 <- where절(SQL)
filter(emp,DEPARTMENT_ID==20) ### 자발적으로 NA가 빠짐! (just like subset())

emp[emp$DEPARTMENT_ID==20,c("LAST_NAME","SALARY")]
filter(emp,DEPARTMENT_ID==20)[,c("LAST_NAME","SALARY")]
filter(emp,DEPARTMENT_ID==20)[,2:5]
filter(emp,DEPARTMENT_ID==30 & SALARY>=3000)[,1:5]

## select: 여러 컬럼이 있는 데이터프레임에서 특정 컬럼만 선택사용 
select(emp,LAST_NAME,SALARY)
select(emp,1,2)
select(emp,1:5)
select(emp,2,4,6)
select(emp,-SALARY,-COMMISSION_PCT)

## %>%: 여러 문장을 조합해서 사용하는 방법을 제공 
emp %>% select(LAST_NAME,JOB_ID,SALARY) %>% filter(SALARY >= 2000) ### 열 추출(select)부터 한 다음, 행 제한(filter) 
emp %>% select(LAST_NAME,JOB_ID,SALARY) %>% filter(SALARY >= 10000) %>% head(3)
emp %>% select(LAST_NAME,JOB_ID,SALARY) %>% filter(SALARY >= 10000) %>% arrange(SALARY) ### arrange(): 정렬(오름차순)
emp %>% select(LAST_NAME,JOB_ID,SALARY) %>% filter(SALARY >= 10000) %>% arrange(desc(SALARY)) ### 내림차순 

## mutate: 새로운 컬럼을 추가
emp$SAL <- emp$SALARY * 12 ### 컬럼 추가 
emp$SAL <- NULL ### 컬럼 삭제 

df <- mutate(emp,sal=SALARY * 12)
str(df)

emp %>% 
  select(LAST_NAME,JOB_ID,SALARY,COMMISSION_PCT) %>% 
  mutate(ANNUAL_SAL = SALARY * 12 + ifelse(is.na(COMMISSION_PCT),0,SALARY*COMMISSION_PCT)) %>% 
  arrange(desc(ANNUAL_SAL))

emp %>% 
  select(LAST_NAME,JOB_ID,SALARY,COMMISSION_PCT,DEPARTMENT_ID) %>% 
  mutate(ANNUAL_SAL = SALARY * 12 + ifelse(is.na(COMMISSION_PCT),0,SALARY*COMMISSION_PCT)) %>% 
  arrange(DEPARTMENT_ID,desc(ANNUAL_SAL)) ### DEPARTMENT_ID 오름차순, ANNUAL_SAL 내림차순 

## summarise: 주어진 데이터 집계 
### data.frame으로 리턴(컬럼의 타입도 보여줌!)
emp %>% summarise(sum_sal=sum(SALARY),mean_sal=mean(SALARY)) ### 여러 집계값을 나열하는 것이 가능! 
emp %>% summarise(max_sal=max(SALARY),min_sal=min(SALARY))
emp %>% group_by(DEPARTMENT_ID) %>% summarise(sum_sal = sum(SALARY), mean_sal = mean(SALARY)) ### group_by(): 부서 별로 집계!(NA도 포함됨!) => data.frame
emp %>% group_by(JOB_ID) %>% summarise(sum_sal = sum(SALARY), mean_sal = mean(SALARY))
emp %>% group_by(DEPARTMENT_ID,JOB_ID) %>% summarise(sum_sal = sum(SALARY), mean_sal = mean(SALARY)) ### 2개의 컬럼에 대한 집계도 가능! 
emp %>% summarise_at(c("SALARY","COMMISSION_PCT"),sum,na.rm=T) ### summarise_at(): 각각의 그룹(컬럼)에 대한 sum을 하라는 뜻! (SALARY에 대한 sum, COMMISSION_PCT에 대한 sum)
emp %>% summarise_if(is.numeric,sum,na.rm=T) ### numeric 타입에 대해서는 sum 수행 





##################################################################################################
##################################################################################################
##################################################################################################





# 08/03/2018

sales <- fruits ; View(sales)
str(sales)
### 가로 모양을 세로 모양으로 바꾸는 함수

install.packages('reshape2')
library(reshape2)

# melt(): 컬럼이 많은 형태(wide)를 세로 방향 긴(long) 형태로 변경
## 열이 행 값으로 들어감 
melt(sales,id='year') ### year를 기준으로 해서 name까지 variable에 들어감! => variable과 value라는 별도의 컬럼이 만들어짐!(기존에 열이었던 name, year, qty, price가 행 값으로 들어감!)
melt(sales,id='name') ### name 기준
m <- melt(sales,id=c('year','name')) ; m

# dcast(): long(세로 방향)을 wide(가로 방향) 형태로 바꿔줌
## 변수 별 집계 가능!
dcast(m, year+name ~ variable) ### 원 위치! 
dcast(m, name ~ variable, sum) ### 집계도 가능!! 
dcast(m, year ~ variable, sum)



'''
■ grep함수 : 문자 패턴을 찾을 때 사용되는 함수 

^ : 첫번째 
$ : 마지막
. : 한자리수
* : wild card(%)

<예>
  emp[grep("aa", emp$LAST_NAME),c("LAST_NAME","SALARY")]

emp[grep("[x-z]", emp$LAST_NAME, ignore.case = TRUE),c("LAST_NAME","SALARY")]

ignore.case = TRUE 대소문자 구분안한다.
ignore.case = FALSE 대소문자 구분한다.
'''
# grep(): 동일한 문자열을 문자열 벡터에서 찾아서 인덱스 번호를 리턴하는 함수 
## grep('문자열',데이터) -> 인덱스 번호
## grep('문자열',데이터,value = TRUE) -> 실제 데이터값 
text <- c('a','ab','acb','accb','accccb')
grep('a',text) ### 인덱스 번호 리턴! -> 한 글자만 넣었을 때는 그 문자가 포함된 모든 요소 번호를 리턴
grep('ab',text) ### 2글자, 3글자 넣을 때는 정확히 일치하는 문자의 요소 번호만 리턴! 
grep('c',text,value = TRUE) ### "value = TRUE": 인덱스가 아닌 실제 값으로 리턴! 

## *: 적어도 0번 매칭하면 찾는다 
grep('ac*b',text,value = TRUE) ### * 앞의 글자: option 글자 <- a와 b는 무조건 포함되어야 하는데, c는 안 나와도 되고, 하나만 나와도 되고, 여러 개가 나와도 됨! 

## +: 적어도 1번 매칭하면 찾는다 
grep('ac+b',text,value = TRUE)

## ?: 최대 1번 매칭하면 찾는다(0번 or 1번 매칭)
grep('ac?b',text,value = TRUE) ### c를 포함하지 않는 문자열도 리턴 

## {}: "바로 앞"에 있는 문자가 {} 안에 있는 숫자만큼 매칭하면 찾는다
grep('ac{2}b',text,value = TRUE) ### {n}: n번 매칭 
grep('ac{3}b',text,value = TRUE)
grep('ac{4}b',text,value = TRUE)

grep('ac{2,}b',text,value = TRUE) ### {n,}: n번 이상 매칭하면 찾는다 
grep('ac{1,4}b',text,value = TRUE) ### {n,m}: n번 이상 m번 이하 매칭하면 찾는다 <- {} 안에 인수값을 3개 넣을 수는 없음! 
grep('ac{,2}b',text,value = TRUE) ### {,n}: n번 이하 매칭하면 찾는다(0~n)



text <- c('abcd','cdab','cabd','c abd')
grep('ab',text,value = TRUE)
grep('^ab',text,value = TRUE) ### ^: 시작(ab로 시작) cf. 'c abd' <- ab 앞에 공백 문자가 있음(리턴되지 않음!)
grep('ab$',text,value = TRUE) ### $: 끝(ab로 끝나는 거)

## \\b: 공백 문자 뒤에 있는 것들도 같이 리턴 <- ^와의 차이점에 주목! 
grep('\\bab',text,value = TRUE) ### \\b: ab로 시작되는 글자들 중에, blank 뒤에 있는 것들도 리턴('c abd'도 리턴됨!) <- ^ vs. \\b



text <- c('^ab','ab','abc','abd','abe','ab 12', '$ab')
grep('ab',text,value = TRUE)
grep('^ab',text,value = TRUE) ### '^ab' 제외
grep('\\bab',text,value = TRUE) ### '^ab' 포함

## .: 어떤 문자 하나 매칭 
grep('ab.',text,value = TRUE) ### .: ab 뒤에 무조건 문자 하나는 와야 함!(공백 문자도 적용됨)

## [n,m]: [..] 리스트 안에 있는 문자 매칭  
grep('ab[c,e]',text,value = TRUE) ### [c,e]: ab 뒤에 c 또는 e가 와야 함! 

## [n-m]: n부터 m까지 문자 매칭 
grep('ab[c-e]',text,value = TRUE) ### c부터 e까지!(d 포함!!)

## [^n]: NOT의 의미! 
grep('ab[^c]',text,value = TRUE) ### 세번째 위치에 c만 아니면 다 리턴! 

grep('[a-z]',text,value = TRUE)
grep('^[a-z]',text,value = TRUE)
grep('[^(a-z)]',text,value = TRUE)
text

## \\특수문자: 특수문자로 시작되는 글자를 리턴 
grep('\\^',text,value = TRUE) ### \\^: ^로 시작되는 글자를 찾는다
grep('\\$',text,value = TRUE)
grep('$',text,value = TRUE) ### 그냥 모든 걸 다 찾음 => $만 포함된 문자를 찾고 싶으면, \\를 사용해야 함! 



text <- c('sql','SQL','Sql100','PLSQL','plsql','R','r','r0','python','PYTHON','pyth0n','python#','100')
text <- c('sql','SQL','Sql100','PLSQL','plsql','R','r','r0','python','PYTHON','pyth0n','python#','100','*','$','^')
text <- c('sql','SQL','Sql100','PLSQL','plsql','R','r','r0','python','PYTHON','pyth0n','python#','100','*','$','^','+','*100','$$','#$%','ひらかな','漢字','한글','★')
grep('[0-9]',text,value = T) ### 숫자열이 포함된 모든 요소 리턴 <- 알파벳 o를 숫자 0으로 잘못 기입한 것들을 추출할 때 쓰임! 
grep('[[:digit:]]',text,value = T) ### 숫자가 포함된 요소 리턴 <- 위의 [0-9]의 결과와 같음 
grep('[[:upper:]]',text,value = T) ### 대문자만 리턴
grep('[[:lower:]]',text,value = T) ### 소문자만 리턴
grep('[[:alpha:]]',text,value = T) ### char 타입만 리턴
grep('[[:alnum:]]',text,value = T) ### 숫자까지 리턴! (alpha + number)
grep('[[:punct:]]',text,value = T) ### 구두점이 포함된 문자열 리턴(, . # 등등)

text[gregexpr('[*|$|^]',text) == 1]
text[which(gregexpr('[*|$|^]',text) == 1)] 

setdiff(text[gregexpr('[*|$|^]',text) == 1], grep('[[:digit:]]',text,value = T)) ### '*100' 제외! 

x <- unlist(strsplit(grep('[[:punct:]]',text,value = T), split = "")) ; x
x[-grep('[a-z]',x)]

x <- grep('[^[:alnum:]]$',text,value = T) ; x
y <- grep('^[^[:alnum:]]',text,value = T) ; y
intersect(x,y)
grep('^*[^[:alnum:]]*$',text,value = T)
grep('^*[[:punct:]]*$',text,value = T)



grep('Steven',emp$FIRST_NAME,value = T)
grep('Stephen',emp$FIRST_NAME,value = T)
grep('Steven|Stephen',emp$FIRST_NAME,value = T)
gregexpr('Ste(v|ph)en',emp$FIRST_NAME)==1 ### 위치값(TRUE or FALSE)
emp[gregexpr('Ste(v|ph)en',emp$FIRST_NAME)==1,] ### 튜플 검색 

x <- c('Steven','Stephen')
grep(x,emp$FIRST_NAME,value = T) ### 오류!
grep(paste(x,collapse = "|"),emp$FIRST_NAME,value = T)



# stringr 패키지 
# str_detect(): 특정 문자가 있는지를 검사해서 TRUE/FALSE를 출력하는 함수 
## 글자 찾는 거(grep()와 기능 비슷)
## grep처럼 ^,.,$ 기능 사용 가능! 
text
str_detect(text,'SQL') ### text 변수 안에 'SQL'이라는 문자만 찾는 거 -> TRUE/FALSE
text[str_detect(text,'SQL')] ### 실제 데이터값 리턴
which(str_detect(text,'SQL')) ### 인덱스 
str_detect(text,'^s') ### 소문자 s로 시작되는 녀석들 보는 거
text[str_detect(text,'n$')]
text[str_detect(text,'^[sS]')] ### 대문자 S 또는 소문자 s로 시작하는 거 
text[str_detect(text,'[qQ]')] ### 대문자 Q 또는 소문자 q를 포함하는 거
text[str_detect(text,regex('s', ignore_case = T))]
text[str_detect(text,'[sS]')]

## str_count(): 주어진 단어에서 해당 글자가 몇 번 나오는지 알려주는 함수 
text <- c('sqls','ssqls')
str_count(text,'s') ### 첫번째 요소에 s가 2개 포함되어 있고, 두번째 요소에 3개 포함되어 있음을 알려줌! 
str_count(text,'S') ### 대소문자 구분! 
str_count(text,'[sS]') ### 대문자 S와 소문자 s 모두 반영! 

## str_c(): 문자열 합쳐서 출력하는 함수 <- paste0()
str_c('R','빅데이터 분석')
text <- 'R'
str_c('프로그램 언어 : ',text)
str_c(text,' 은 데이터 분석하기 위해 좋은 언어는 ',text,'이다')
text <- c('R','빅데이터 분석')
str_c(text,collapse=' ')
str_c(text,collapse=',') ### collapse 작업하고 싶으면, 벡터 변수에 따로 집어 넣어서 str_c() 함수를 수행해야 함! 

## str_dup(): 주어진 문자열을 주어진 횟수만큼 반복해서 출력하는 함수
str_dup('파도 소리 듣고 싶다',10) ### 10번 반복 

## str_length(): 주어진 문자열의 길이를 출력하는 함수
str_length('해운대가고싶다')

## str_locate(): 주어진 문자열에서 특정 문자가 처음으로 나오는 위치 
str_locate('january','a') ### start: 처음으로 나오는 위치
str_locate_all('january','a') ### 끝에 나오는 위치까지 확인 가능 
str_locate_all('janauary','a') ### 중간에 나오는 위치도 확인 가능! 

## str_replace(): 주어진 문자열에서 변경 전 문자를 변경 후 문자로 바꾸는 함수 
### str_replace(원본,기존문자열,새로운문자열)
str_replace('빅데이터분석','빅데이터','가치')
str_replace('banana','a','*') ### 첫번째 것만 바뀜 
str_replace_all('banana','a','*')

## str_split(): 주어진 데이터셋에서 지정된 기호를 기준으로 분리하는 함수 cf. str_c(): 합치는 거
str <- str_c('sql','/','plsql','/','r')
str_split(str,'/') ### /를 기준으로 분리 
str

## str_sub(): 주어진 문자열에서 지정된 길이 만큼의 문자를 잘라내는 함수 
str_sub('행복하게 살자',start=1,end=2) ### 첫번째 글자에서 두번째 글자까지만 뽑아내고, 나머지는 다 자름! 
str_sub('행복하게 살자',start=-2) ### 젤 뒤에 두 글자 <- start에 -(minus) 붙임 
str_sub('행복하게 살자',start=1) ### end 표현 안 하면, 그냥 끝까지 다 표현! 

'        R        ' ### 공백문자도 문자로 인식! 

## str_trim(): 접두, 접미 부분에 공백 문자를 제거하는 함수 
str_trim('        R        ') ### 공백 문제 다 제거됨! 





##################################################################################################
##################################################################################################
##################################################################################################





# 08/06/2018

# 통계학
## - 관심대상에 대해 관련된 데이터를 수집하고 그 데이터를 요약, 정리하여 이로부터 불확실한 사실에 대한 결론이나 일반적인 규칙성을 찾는 학문이다.
## - 해결하고 싶은 문제가 있기에 그에 따른 답을 찾기 위해서 분석을 한다. 

# 자료(Data)
## - 문제해결을 위한 원재료로서 처리되지 않은 숫자, 문자, 일련의 사실이나 기록들의 모임
## - 어떠한 가치 판단을 할 수 있는 근거가 되는 재료

# 양적 자료 <- 사칙 연산 가능 
## - 숫자, 크기가 관심, 측정되는 값
## - 연속형 자료 ex. 키, 몸무게 <- 소수점!(하나의 숫자로 딱 떨어지지 않음)
## - 이산형 자료 ex. 출생아 수, 남학생 수, 왼손잡이 수 <- 하나의 수로 딱 떨어지는 값

# 질적 자료 <- 범주형 
## - 자료의 내포하고 있는 의미가 있을 경우
## - 순위형 자료: 학점(A,B,C,D,F), 매우그렇다, 보통이다 <- 의미가 있으면서 순서가 있는 경우(ordered)
## - 명목형 자료: 성별구분(남,여), 거주지역, 혈액형 <- factor

'''
                요약방법            자료정리              그래프
-----------------------------------------------------------------------
질적 자료     도표, 그래프      도수분포표(table)        막대그래프
                                    분할표                원그래프
-----------------------------------------------------------------------
양적 자료     수치, 그래프     평균, 분산, 표준편차      히스토그램
                               중앙값, 최빈값             boxplot
                               최소값, 최대값, 4분위수   시계열도표
                                                         scatter plot
'''
### 시각화(Visualisation) -> "자료정리"를 "그래프"로 만듬! 

# 기술통계(지금까지 해온 거!)
## - 자료를 수집, 정리
## - 자료 형태를 표현 
## - 자료의 특성값을 도출 

### select dept_id, count(*) <- 도수분포표! => 이걸 "시각화"해야!!! 

# 추측통계
## - 표본으로부터 관찰하고자 하는 특성값 도출
## - 이를 바탕으로 모집단의 특성 파악 



# Pie chart
## pie(값, labels = 카테고리, main = "제목", col=c('색깔'))
## - 질적자료에 대한 상대도수분포를 나타내기 위해 일반적으로 사용되는 원 그래프
## - 원을 그린 후 그 원에 각 계급의 상대도수에 대응하는 면적 또는 부분으로 나눈다. 

# Simple Pie Chart
slices <- c(10, 12,4, 16, 8)
lbls <- c("US", "UK", "Australia", "Germany", "France")
pie(slices, labels = lbls, main="Pie Chart of Countries", col=default(5))
?colour
### A 회사 : 100억
### B 회사 : 50억
### C 회사 : 30억
### D 회사 : 10억

s <- c(100,50,30,10)
company <- c("A회사", "B회사", "C회사", "D회사")
pie(s, labels = company, main="회사 별 매출액")
pie(s, labels = company, main="회사 별 매출액", col=c('red','blue','green','yellow'))

### rainbow(): 무지개색
### heat.colors(12): 적색, 황색에 치우친 색
### terrain.colors(12): 지구 지형색 
### topo.colors(12): 청색에 가까운 색
### cm.colors(12): 핑크, 블루
pie(s, labels = company, main="회사 별 매출액", col = rainbow(length(s))) ### rainbow(숫자) 이용! 
pie(s, labels = company, main="회사 별 매출액", col = topo.colors(12))
pie(s, labels = company, main="회사 별 매출액", col = cm.colors(12))
?pie

## clockwise
### 시계 방향(TRUE)으로 회전할 지 반시계 방향(FALSE)으로 회전할 지 지정
pie(s, labels = company, main="회사 별 매출액", col = rainbow(length(s)), clockwise = F) ### Default(반시계 방향)
pie(s, labels = company, main="회사 별 매출액", col = rainbow(length(s)), clockwise = T)

## init.angle
### clockwise가 반시계 방향(FALSE) 3시 방향 
### clockwise가 시계 방향(TRUE) 12시 방향 
pie(s, labels = company, main="회사 별 매출액", col = rainbow(length(s)), clockwise = F, init.angle = 90) ### 처음 시작하는 각도 지정 
pie(s, labels = company, main="회사 별 매출액", col = rainbow(length(s)), clockwise = T, init.angle = 45)

## 파이에 대한 크기(percentage)를 넣고 싶은 경우 
# Pie Chart with Percentages
slices <- c(10, 12, 4, 16, 8) 
lbls <- c("US", "UK", "Australia", "Germany", "France")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct) # add percents to labels 
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(slices,labels = lbls, col=rainbow(length(lbls)), main="Pie Chart of Countries")

p <- round(s/sum(s)*100) ; p
label <- paste0(company," ",p,"%") ; label
pie(s, labels = label, main="회사 별 매출액", col = rainbow(length(s)), clockwise = F)

## pie chart를 그릴 때는 되도록이면 범례(legend) 사용! 
legend(-1.2,-.3,x$DEPARTMENT_NAME,fill = rainbow(length(x$dept_sum)))

# 3D Exploded Pie Chart
install.packages('plotrix')
library(plotrix)
slices <- c(10, 12, 4, 16, 8) 
lbls <- c("US", "UK", "Australia", "Germany", "France")
pie3D(slices,labels=lbls,explode=0.1,main="Pie Chart of Countries ")

pie3D(s,labels = label,explode = 0.1,labelcex = 0.8)
### explode: 부채꼴들의 간격 (0: 간격 없이 붙어 있음)
### labelcex: label의 문자 크기 



# 막대그래프
## - 질적 자료를 표현하는 그래프 
## - 각 계급 이름 위에 고정 너비의 막대를 그리고 도수에 따라 적절하게 막대의 길이를 표현한다. 

# Simple Bar Plot 
counts <- table(mtcars$gear)
barplot(counts, main="Car Distribution", 
        xlab="Number of Gears")

sales <- c(150,100,70,30)
team <- c("영업1팀","영업2팀","영업3팀","영업4팀")
barplot(height = sales, width = 0.5, names.arg = team, 
        horiz = FALSE, col = rainbow(length(sales)), 
        main = "영업팀별 영업 실적", sub = "2018년도",
        xlab = "영업팀", ylab = "영업실적(억원)", 
        ylim = c(0,180))
barplot(height = sales, width = 35, names.arg = team, 
        horiz = TRUE, col = rainbow(length(sales)), 
        main = "영업팀별 영업 실적", sub = "2018년도",
        xlab = "영업팀", ylab = "영업실적(억원)", 
        ylim = c(0,180))
### height: 막대 크기를 나타내는 벡터(숫자 형식) -> 막대 그래프를 표현하는 값(숫자가 들어가는 벡터 변수로 표현!)
### width: 막대 너비(폭)
### names.arg: 막대 아래 출력되는 이름 
### col: 막대 색상 
### main: 제목 
### sub: 부제목 
### horiz: TRUE(수평막대), FALSE(수직막대)
### xlab: x축 이름
### ylab: y축 이름
### ylim: y축 크기 <- 막대의 길이가 너무 길다 싶으면 ylim을 줄일 것! 
### xlim: x축 크기

bp <- barplot(height = sales, width = 0.5, names.arg = team, 
        horiz = FALSE, col = rainbow(length(sales)), 
        main = "영업팀별 영업 실적", sub = "2018년도",
        xlab = "영업팀", ylab = "영업실적(억원)", 
        ylim = c(0,180))
label <- paste(sales,'억원',sep="")
text(x=bp,y=sales,labels=label,pos=3) ### 막대마다 각각의 수치를 표현! 
### pos = 1: 막대 끝 선의 아래쪽
### pos = 2: 막대 끝 선의 왼쪽
### pos = 3: 막대 끝 선의 위쪽
### pos = 4: 막대 끝 선의 오른쪽



# Stacked bar chart(스택형 바 차트) <- 누적! 

# Stacked Bar Plot with Colors and Legend
counts <- table(mtcars$vs, mtcars$gear)
barplot(counts, main="Car Distribution by Gears and VS",
        xlab="Number of Gears", col=c("darkblue","red"),
        legend = rownames(counts))

x1 <- c(2,6,9,5)
x2 <- c(8,10,15,6)
data <- rbind(x1, x2) ; data
name <- c("영업1팀","영업2팀","영업3팀","영업4팀")
label <- c("2016년","2017년")

barplot(data, names.arg = name, main = "영업팀별 영업 실적", 
        xlab = "영업팀", ylab = "판매실적(억원)", ylim = c(0,30), 
        col = c("darkblue","pink")) ### BUT 어떤 연도의 값인지 모름! => 색상 별로 legend 표현! 
barplot(data, names.arg = name, main = "영업팀별 영업 실적", 
        xlab = "영업팀", ylab = "판매실적(억원)", ylim = c(0,30), 
        col = c("darkblue","pink"), 
        legend.text = label)





##################################################################################################
##################################################################################################
##################################################################################################





# 08/07/2018

# Grouped Bar Chart <- "beside=TRUE"

# Grouped Bar Plot 
counts <- table(mtcars$vs, mtcars$gear)
barplot(counts, main="Car Distribution by Gears and VS",
        xlab="Number of Gears", col=c("darkblue","red"),
        legend = rownames(counts), beside=TRUE)

barplot(data, names.arg = name, main = "영업팀별 영업 실적", 
        xlab = "영업팀", ylab = "판매실적(억원)", ylim = c(0,20), 
        col = c("darkblue","pink"), legend = label, beside=TRUE)





##################################################################################################
##################################################################################################
##################################################################################################





# 08/09/2018

# 자료(Data)
## - 문제해결을 위한 원재료로서 처리되지 않은 숫자, 문자, 일련의 사실이나 기록들의 모임
## - 어떠한 가치 판단을 할 수 있는 근거가 되는 재료

# 양적 자료
## - 숫자, 크기가 관심, 측정되는 값
## - 연속형 자료 ex. 키, 몸무게 <- 소수점!(하나의 숫자로 딱 떨어지지 않음)
## - 이산형 자료 ex. 출생아 수, 남학생 수, 왼손잡이 수 <- 하나의 수로 딱 떨어지는 값

# 질적 자료
## - 자료의 내포하고 있는 의미가 있을 경우
## - 순위형 자료: 학점(A,B,C,D,F), 매우그렇다, 보통이다 <- 의미가 있으면서 순서가 있는 경우(ordered)
## - 명목형 자료: 성별구분(남,여), 거주지역, 혈액형 <- factor

'''
                요약방법            자료정리              그래프
-----------------------------------------------------------------------
질적 자료     도표, 그래프      도수분포표(table)        막대그래프(barplot)
(qualitative)                        분할표                원그래프
-----------------------------------------------------------------------
양적 자료     수치, 그래프     평균, 분산, 표준편차      히스토그램
(quantitative)                  중앙값, 최빈값             boxplot
                              최소값, 최대값, 4분위수    시계열도표
                                                        scatter plot
'''

# 분할표(contingency table)
## - 명목형(categorical), 순서형(순위형)(ordinal) 데이터의 도수(frequency)를 표 형태로 나타내는 것을 의미한다. 

x <- c('A','B','A','B','B','C')

## 데이터의 빈도수(도수)를 파악할 수 있는 하나의 기능
### 유일키 값을 기준으로 각각의 건수가 나옴! 
table(x) ### table(): 분할표를 만드는 메소드 

## 최대값이 저장된 위치의 색인을 반환 
which.max(table(x)) ### which.max(): 도수가 가장 큰 값과 위치 정보가 나옴! 

which.min(table(x)) ### which.min(): 최소값과 그 위치 정보 

names(table(x)) ### 셀 목록 확인 
names(table(x))[2]

## table을 이용해 각 컬럼의 도수분포를 쉽게 파악 가능! 
table(emp$JOB_ID)
table(emp$DEPARTMENT_ID)

## xtabs(): formula(~)를 이용해 분할표 작성 <- table()과 같은 기능! 
xtabs(~JOB_ID, emp)

### 여러 개의 컬럼을 가지고 분석해야 할 때는, 벡터를 써야 할 지, list를 써야 할 지 꼭 생각해볼 것! 
table(c(emp$JOB_ID,emp$DEPARTMENT_ID))
table(list(emp$JOB_ID,emp$DEPARTMENT_ID)) ### 더 정리정돈이 잘 되어 있음! (cross table)

xtabs(~JOB_ID+DEPARTMENT_ID,emp) ### 위의 table(list)와 같은 모양, 기능 

### 지금까지는 sql의 count() 기능만 사용한 거! 

## 집계값을 사용하는 법
xtabs(SALARY~JOB_ID+DEPARTMENT_ID,emp) ### SALARY에 대한 합이 구해짐! (aggregate()의 기능! 분할표 형식으로 볼 수 있음!)
aggregate(SALARY ~ JOB_ID+DEPARTMENT_ID, emp, sum)



## margin.table(): 분할표의 행의 합, 열의 합을 구하는 방법 
x <- xtabs(SALARY~JOB_ID+DEPARTMENT_ID,emp) 
y <- margin.table(x,1) ### 1: 행 방향으로 합을 구함! 
z <- margin.table(x,2) ### 2: 열 방향으로 합을 구함! 

## prop.table(x,1): 행 방향으로 상대적인 비율값 계산
prop.table(x,1)

## prop.table(x,2): 열 방향으로 상대적인 비율값 계산
round(prop.table(x,2),2)

## prop.table(): 분할표 전체의 비율 계산(margin 삭제)
prop.table(x)



# 산점도(scatter plot)
## - 주어진 데이터를 점으로 표시해 흩뿌리듯이 시각화한 그래프(분산)
## - 데이터의 실제 값들이 표시되므로 데이터의 분포를 한 눈에 살펴보는데 유용하다. 
## 산포도 -> 상관분석! (두 변수의 상관관계)

data() ### R에 내장되어 있는 데이터셋 확인 가능 
help(women) ### 해당 데이터셋에 대한 정보 확인 가능

str(women)
plot(women$weight)
plot(women$height)

plot(x=women$height, y=women$weight, xlab="키", ylab="몸무게", main="여성의 키와 몸무게", sub="미국의 70년대 기준",
     type="p", lty = 4, lwd = 2, pch = 25, cex = 1.5)
## type
### p: 점, l: 선, b: (점, 선), c: (b의 선 부분만), o: 점 위의 선, h: 수직선, s: 계단형, n: 나타나지 않음

## lty: 선의 유형(1~6) 
'''
0: 그리지 않음
1: 실선(default)
2: 대시(-)
3: 점
4: 점과 대시
5: 긴 대시
6: 두 개의 대시
'''

## lwd: 선의 굵기(default = 1)
## pch: 점의 종류(0~25)
## cex: 점의 크기(default = 1)


# 도수분포표 (frequency distribution), frequency table
## 미리 구간을 설정해 놓고 각 구간의 범위 안에 조사된 데이터 값들이 몇개씩 속하는가를 표시하는 표 
'''
-계급: 각 구간
-도수: 각 구간(계급)에 속한 데이터 값들의 수
-상대도수: 어느 계급에 속한 도수가 전체 도수에 차지하는 비율
-누적도수: 어느 계급의 도수와 그 위의 계급에 속한 도수를 모두 합하여 구하며 이러한 누적도수를 각 계급별로 표시 
'''

## 계급의 수의 결정
'''
계급수 = 자료의 측정값들의 갯수^(1/3)
ex) length(score)^(1/3)

급간 = (가장 큰 측정값 - 가장 작은 측정값) / 계급 수 
ex) (max(score)-min(score))/length(score)^(1/3)

※위의 결정방법은 법칙이 아니라 참고사항
'''
?cut ### divides the range of x into intervals
?nclass.Sturges ### Compute the number of classes for a histogram.

#Fake data
x <- sample(10:20, 44, TRUE)
#Your code
factorx <- factor(cut(x, breaks=nclass.Sturges(x)))
#Tabulate and turn into data.frame
xout <- as.data.frame(table(factorx)) ### as.data.frame() <- 이게 핵심! (Freq 구하는 방법)
#Add cumFreq and proportions
xout <- transform(xout, cumFreq = cumsum(Freq), relative = prop.table(Freq))
#-----
'''
factorx Freq cumFreq   relative
1 (9.99,11.4]   11      11 0.25000000
2 (11.4,12.9]    3      14 0.06818182
3 (12.9,14.3]   11      25 0.25000000
4 (14.3,15.7]    2      27 0.04545455
5 (15.7,17.1]    6      33 0.13636364
6 (17.1,18.6]    3      36 0.06818182
7   (18.6,20]    8      44 0.18181818
'''





##################################################################################################
##################################################################################################
##################################################################################################





# 08/10/2018

# 도수분포표 -> 질적 자료, non-categorical

# cut()
## 연속형 자료를 categorical하게 변환하는 함수 
## 연속형 변수를 범주형 변수로 변환 

# 도수분포표는 자료의 중요한 특성을 서술적 방법으로 나타내는데 효과적이고
# 이를 시각화하려면 "히스토그램"을 사용하면 된다. -> 자료의 분포도! 

'''
The Difference Between Bar Charts and Histograms

Here is the main difference between bar charts and histograms. 
With bar charts, each column represents a group defined by a categorical variable; 
and with histograms, each column represents a group defined by a continuous, quantitative variable.

One implication of this distinction: it can be appropriate to talk about the skewness of a histogram; 
that is, the tendency of the observations to fall more on the low end or the high end of the X axis.

With bar charts, however, the X axis does not have a low end or a high end; 
because the labels on the X axis are categorical - not quantitative. 
As a result, it is not appropriate to comment on the skewness of a bar chart.
'''

#Fake data
score ### 연속형 변수 -> 이걸 cut()을 통해 범주형 변수로 바꿔줌! 

# Your code
scoref <- factor(cut(score, breaks=nclass.Sturges(score))) ; scoref

c <- cut(score, breaks = c(60,70,80,90,100), right=FALSE, 
    labels = c("60점이상~70점미만","70점이상~80점미만","80점이상~90점미만","90점이상")) ; c ### 연속형 자료가 전부 categorical하게 바뀜! 
c <- cut(score, breaks = seq(60,100,10), right=FALSE, 
         labels = c("60점이상~70점미만","70점이상~80점미만","80점이상~90점미만","90점이상")) ; c 
table(c) ### 도수 확인 가능! 
## cut:: right=FALSE <- "60<= ~ <70" or "[60,70)" (~ 이상, ~ 이하)
##       right=TRUE <- "60< ~ <=70" or "(60,70]" (~ 이하, ~ 이상)

## 도수분포표
c.table <- table(c)
## 상대도수분포표
c.prop <- prop.table(c.table)

cbind(c.table, c.prop)

## 도수분포표(cut())를 사용할 때는, 히스토그램 사용! 
hist(score, breaks = seq(60,100,10), right = FALSE, col = rainbow(4))
### 60과 70 사이에 63이 몇 개인지, 65가 몇 개인지 디테일한 자료 구성을 확인하고 싶으면, 줄기잎 그림 사용! 

## 줄기 잎 그림(stem and leaf diagram)
### - 서술적인 면과 그래프의 시각적인 면을 동시에 고려하여 자료의 특성을 나타낼 때 사용 
### - 자료를 구성하는 각각의 데이터 값들의 줄기(stem)와 잎(leaf)으로 구분 
stem(score) ### 줄기 | 잎 <- 정수형만 사용할 것!(소수점은 반올림됨)

heig <- c(178.5,193.6,134.8,147.36,159.1)
stem(heig) 

# Tabulate and turn into data.frame
sout <- as.data.frame(table(scoref)) ; sout ### as.data.frame() <- 이게 핵심! (Freq 구하는 방법)

# Add cumFreq and proportions
scout <- transform(sout, cumFreq = cumsum(Freq), relative = prop.table(Freq)) ; scout



# Google Map
install.packages('ggmap')
library(ggmap)

## geocode("지역명 또는 주소"): 위도, 경도값을 반환하는 함수 
gc <- geocode(enc2utf8("서울시")) ### enc2utf8(): 한글을 utf8 형식으로 변환하는 함수 
### lon: longitude(경도) // lat: latitude(위도)

map <- get_googlemap(center = as.numeric(gc), zoom = 18, maptype = "satellite")
ggmap(map)

'''
center: 지도 좌표값
zoom: 지도 크기 기본값(10 도시), 3(대륙) ~ 21(빌딩)
size: 지도 가로 세로 픽셀 크기 640 x 640, size = c(640,640)
mapsize: 지도 유형
         terrain(지형정보기반), satellite(위성지도), roadmap(도로명표시), hybrid(위성, 도로명)
marker: 위도 경도 위치에 마커 출력
ggmap: 지도를 출력하는 함수 
'''

## 2개 이상의 지역 검색 
names <- c("1.협재해수욕장","2.함덕해수욕장")
addr <- c("제주특별자치도 제주시 한림읍 협재리 2497-1","제주특별자치도 제주시 조천읍 함덕리 1008")
gc <- geocode(enc2utf8(addr)) ; gc
df <- data.frame(name = names, lon = gc$lon, lat = gc$lat) ; df
cen <- c(mean(df$lon), mean(df$lat)) ; cen

map <- get_googlemap(center = cen, zoom = 10, maptype = "roadmap", markers = gc)
ggmap(map) ### 이걸 해야 지도 보여줌!!! 

gc <- geocode(enc2utf8("도쿄도")) 
map <- get_googlemap(center = as.numeric(gc), zoom = 16, maptype = "hybrid", markers = gc)
ggmap(map)

cen <- c(2.294481, 48.85837)
ggmap(get_googlemap(center = cen, maptype = "roadmap", zoom = 15, 
                    markers = data.frame(lon = 2.294481, lat = 48.85837)))

gc <- geocode(enc2utf8("시카고")) 
map <- get_googlemap(center = as.numeric(gc), zoom = 16, maptype = "hybrid", markers = gc)
ggmap(map)



# 지도를 이용해서 CCTV 위치 파악 
## https://www.data.go.kr/
cctv <- read.csv("C://data/cctv.csv")
View(cctv)
cctv2 <- sample_n(cctv, 80)
cen <- c(mean(cctv2$경도), mean(cctv2$위도)) ; cen
map <- get_googlemap(center = cen, zoom = 14, maptype = "roadmap", markers = cctv2[,c("경도","위도")])
ggmap(map)

cctv <- read.csv("C://data/cctv.csv")
View(cctv)
cctv2 <- cctv[grep('삼성로',cctv$소재지도로명주소),] ### 해당 지역에 한정지어서 cctv 위치 파악 
cen <- c(mean(cctv2$경도), mean(cctv2$위도)) ; cen
map <- get_googlemap(center = cen, zoom = 14, maptype = "roadmap", markers = cctv2[,c("경도","위도")])
ggmap(map)

## ggplot2 이용
map <- get_googlemap(center = cen, zoom = 14, maptype = "roadmap")
ggmap(map) + geom_point(data = cctv2, aes(x=cctv2$경도, y=cctv2$위도), size=5, alpha = 0.3, color="red")

### Error: max url length is 2048 characters. <- markers로 찍을 수 있는 개수 제한! 
### BUT ggplot2 쓰면 찍어는 줌! (일부 데이터는 자동적으로 지움)





##################################################################################################
##################################################################################################
##################################################################################################





# 08/13/2018

# Animation
myAni <- function(){
  for (i in 10:0){
    plot.new()
    rect(0,0,1,1,col = "gold") ### rectangle: 사각선 
    text(0.5,0.5,i,cex = 10,col = rgb(0,0,1,0.5)) ### rgb: 빛의 삼원색 <- rgb(red, green, blue, 0.5) <- 3개의 인자를 다 1로 하면 흰색! 
                                                  ### 0.5: 투명도 <- 투명도 쓰지 않아도 됨! 
    ani.pause()
  }
}
myAni() ### countdown 계산! 

myAni <- function(){
  for (i in 10:0){
    plot.new()
    rect(0,0,1,1,col = "gold") 
    text(0.5,0.5,i,cex = ifelse(i%%2==0,i,-i),col = rgb(0,0,1)) ### cex에 i 변수를 넣어 크기 dynamic하게! 
    ani.pause()
  }
}
myAni()

myAni <- function(){
  for (i in 10:0){
    plot.new()
    rect(0,0,1,1,col = "gold") 
    s <- i-1
    text(0.5,0.5,i,cex = s,col = rgb(0,0,1))
    ani.pause()
  }
}
myAni()

myAni <- function(){
  n <- ani.options("nmax") ### nmax: animation 프레임을 만들기 위한 반복 수(1초의 30개 프레임) 스틸컷, 기본값 50 
  x <- sample(1:n) ### random sampling! 
  y <- sample(1:n)
  
  for (i in 1:n){
    plot(x[i],y[i],cex=3,col="red",lwd=2,ylim=c(0,50),xlim=c(0,50)) ### 좌표 상의 점을 찍음! 
    ani.pause()
  }
}
myAni()

## ani.options(): animation option 설정 조회하는 함수
ani.options()

## interval: animation의 시간 간격(초 단위) 기본값 1초
## nmax: animation 프레임을 만들기 위한 반복 수(1초의 30개 프레임) 스틸컷, 기본값 50 

## ani.width(): 프레임 가로 크기(픽셀)
## ani.height(): 프레임 세로 크기(픽셀)

## ani.pause(): 주어진 시간 동안에 대기하고 현재 화면을 지운다. 
ani.pause("interval") ### 기본값 

## 1. Make graphs
barplot(money, main="영업팀별 영업 매출액",
        xlab="", col=c("skyblue","darkblue","violet", "orange", "blue"),
        ylim=c(0,120), beside = TRUE, cex.names = .7, ylab = "병원 수", las=2,
        legend = team)
pie(money, labels = paste0(team,'\n',money,"억원"), main="영업팀별 영업 매출액", 
    col = c("skyblue","darkblue","violet", "orange", "blue"), clockwise = F, init.angle = 90)
pie3D(money,labels=paste0(team,'\n',money,"억원"),explode=0.1,main="영업팀별 영업 매출액", 
      col = c("skyblue","darkblue","violet", "orange", "blue"), labelcex = 0.7)

## 2. Save files
library(jpeg)

jpeg('C://data/ex170_1.jpeg', width = 400, height = 300, pointsize = 12) ### 이거 실행하고 위의 plot 실행하면 파일 저장됨! 
dev.off() ### save 종료 
jpeg('C://data/ex170_2.jpeg', width = 400, height = 300, pointsize = 12) 
pie(money, labels = paste0(team,'\n',money,"억원"), main="영업팀별 영업 매출액", 
    col = c("skyblue","darkblue","violet", "orange", "blue"), clockwise = F, init.angle = 90)
dev.off()
jpeg('C://data/ex170_3.jpeg', width = 400, height = 300, pointsize = 12) 
pie3D(money,labels=paste0(team,'\n',money,"억원"),explode=0.1,main="영업팀별 영업 매출액", 
      col = c("skyblue","darkblue","violet", "orange", "blue"), labelcex = 0.7)
dev.off()

## 3. Load and animate files 
for (i in 1:3){
  img <- paste("c://data/ex170_",i,".jpeg",sep = "")
  img <- readJPEG(img)
  
  plot.new()
  rect(0,0,1,1,col="white",border = "white") ### 그래픽 프레임 영역 지정 
  rasterImage(img,0,0,1,1) ### 화면에 이미지 출력하는 함수 
  ani.pause() ### 잠깐 대기한 후 화면 지우고 다시 출력 <- 대기 시간 직접 입력할 수 있음 
}

for (i in 1:3){
  img <- paste("c://data/ex170_",i,".jpeg",sep = "")
  img <- readJPEG(img)
  
  plot.new()
  rect(0,0,1,1,col="white",border = "white")
  rasterImage(img,0,0,1,1) 
  ani.pause(10) ### 대기 시간 직접 입력할 수 있음 
}

## rasterImage(): 화면에 이미지 출력하는 함수 
## rasterImage(image, xleft, ybottom, xright, ytop)
### image: 출력할 이미지 파일 이름 
### xleft: 이미지 출력 위치(x축 왼쪽)
### ybottom: 이미지 출력 위치(y축 하단)
### xright: 이미지 출력 위치(x축 오른쪽)
### ytop: 이미지 출력 위치(y축 상단)





##################################################################################################
##################################################################################################
##################################################################################################





# 08/14/2018

install.packages("RJDBC")
library(RJDBC)
jdbcDriver <- JDBC(driverClass="oracle.jdbc.OracleDriver", classPath="C:/data/ojdbc6.jar")
conn <- dbConnect(jdbcDriver, "jdbc:oracle:thin:@localhost:1521/xe", "hr",  "hr")  ### SID: instance name

emp <- dbGetQuery(conn, "select * from employees")

dept <- dbGetQuery(conn, "select * from departments")

class(emp)
View(emp)

## Path 설정 
### 이 경로에 install.packages 저장 
.libPaths() ### Path가 다를 경우, 이 함수를 이용해 설정! 



# GIF 저장 
?saveGIF
for1 <- for (i in gu) {
  img <- paste("c:/data/",i,".jpg",sep="")
  img <- readJPEG(img)
  plot.new()
  rasterImage(img,0,0,1,1)
  ani.pause()
}
saveGIF(for1, movie.name = "animation.gif", img.name = "Rplot", convert = "convert", 
        cmd.fun, clean = TRUE)
install.packages("installr")
library(installr)
install.imagemagick("https://www.imagemagick.org/script/download.php")

saveGIF(for (i in gu) {
  img <- paste("c:/data/",i,".jpg",sep="")
  img <- readJPEG(img)
  plot.new()
  rasterImage(img,0,0,1,1)
  ani.pause()
})

install.packages("devtools")
library(devtools)

dev_mode(on=T)

install.packages('animation', repos = 'http://yihui.name/xran')
library(animation)
saveGIF({
  for (i in 1:10) plot(runif(10), ylim = 0:1)
})

dev_mode(on=F)

install.packages("installr")
library(installr)
install.imagemagick("https://www.imagemagick.org/script/download.php")
install.packages("devtools")
library(devtools)
install_github("yihui/animation")
dev_mode(on=T)
saveGIF(for (i in gu) {
  img <- paste("c:/data/",i,".jpg",sep="")
  img <- readJPEG(img)
  plot.new()
  rasterImage(img,0,0,1,1)
  ani.pause()
})



# ggplot2(package)
library(ggplot2)
df <- read.csv("C://data/exam.csv", header = T, stringsAsFactors = F)
str(df)
x <- df[df$subject == 'SQL',] ; x

## Barplot
ggplot(x, aes(x=name, y=grade)) + 
  geom_bar(stat = "identity", fill = "skyblue", colour = "darkblue") +
  theme(axis.text.x = element_text(angle=45, hjust = 1, vjust = 1, colour = "blue", size = 10)) ### angle: x label 각도 조정 

df1 <- df %>% arrange(name)

## Stacked Barplot("fill = ")
ggplot(df1, aes(x=name, y=grade, fill=subject)) + ### Frame <- "fill=subject": 과목별로 쌓아놓으라는 뜻 
  geom_bar(stat = "identity", colour = "darkblue") + ### Stacked Bar
  geom_text(aes(y=grade,label=paste(grade,"점")), col = "black", size = 4, position = position_stack(vjust=0.5)) + ### 점수 <- "position = position_stack(vjust=0.5)": text의 위치 
  theme(axis.text.x = element_text(angle=45, hjust=1, vjust=1, colour = "blue", size = 10)) +
  ggtitle("itwill 학생 성적", subtitle = "중간고사") + ### Title
  labs(x="이름",y="점수",fill = "과목") ### label의 이름 변경 

### 과목 기준으로 grouping("group = ") 
ggplot(data = df, aes(subject, grade, group = name)) +
  geom_col(aes(fill = name), position = "stack") + ### geom_bar와 geom_col은 같은 기능의 메소드! 
  geom_text(aes(label = grade), position = position_stack(vjust=0.5))

### 이름 기준으로 grouping 
ggplot(data = df, aes(name, grade, group = subject)) +
  geom_col(aes(fill = subject), position = "stack") + 
  geom_text(aes(label = grade), position = position_stack(vjust=0.5))

### Grouped barplot("dodge")
ggplot(data = df, aes(name, grade, group = subject)) +
  geom_col(aes(fill = subject), position = "dodge") + 
  geom_text(aes(label = grade), position = position_dodge(.9), vjust = 1.5) ### "position = position_dodge(1)"





##################################################################################################
##################################################################################################
##################################################################################################





# 08/16/2018

# 선과점 그래프(ggplot + geom_line() + geom_point())
df <- read.csv("C://data/exam.csv", header = TRUE, stringsAsFactors = FALSE)
library(ggplot2)
ggplot(df, aes(x = subject, y = grade, group = name)) + ### color 부분 생략
  geom_line() +
  geom_point()
ggplot(df, aes(x = subject, y = grade, group = name, color = name)) +  
  geom_line() +
  geom_point()



# Text Mining 
text1 <- "R은 오픈소스로 통계, 기계학습, 금융, 생물정보학, 그래픽스에 이르는 다양한 통계 패키지를 갖추고 있는 좋은 프로그램이다." 

strsplit(text1," ")

library(rJava)
install.packages("KoNLP")
library(KoNLP)
??KoNLP
useSejongDic()

extractNoun(text1) ### 한글 명사만 추출하는 함수: 한나눔분석기 <- 한계가 있음! => 사전에 없는 새로운 단어들을 등록해야 함! 

SimplePos09(text1) ### 품사까지 구분! <- 09: 9개의 품사 태그를 달아주는 함수(konlp_tags.png)
SimplePos22(text1) ### 22: 22개의 품사 태그를 달아주는 함(좀 더 세세하게!)

text2 <- SimplePos09(text1) 
text2[grep("N", text2)]
str_replace_all(text2[grep("N", text2)],'/N.*','')

## another solution
text_noun <- str_match(text2, '([A-Z가-R]+/N)')
na.omit(text_noun[,2]) ### NA 필드 모두 제거 
as.vector(na.omit(text_noun[,2])) ### 밑의 부수 정보들(attr) 제거

## 단어 등록 
### 고유명사, 이름, 지명 등
extractNoun(text1)
.libPaths() ### KoNLP_dic으로 이동! => extractNoun() 메소드 사용 시 dic_user 텍스트 파일의 사전 이용! 
useSejongDic() ### 사전 단어들 등록! 
extractNoun(text1)

### extract 했을 때, 원하는 단어가 없으면 아래처럼 수동으로 설치해야 함! 
buildDictionary(ext_dic = "sejong", user_dic = data.frame(c("오픈소스","기계학습","생물정보학","다양한"),c("ncn")), replace_usr_dic = T) ### dictionary data cache(shared pool에 row 단위로 저장) <- semantic 권한 체크 in Oracle 
extractNoun(text1) ### 결과값이 달라짐!! 

## 단어들의 빈도 수 체크 
table(str_replace_all(text2[grep("N", text2)],'/N.*','')) ### 질적 자료 => 평균, 분산 이런 거 못 구함! => 명사 별로 분리 시켜서 빈도 수 체크하는 게 나음! 

jane <- readLines("C://data/jane.txt")
jane2 <- SimplePos09(jane) 
unlist(jane2[grep("N", jane2)]) ### 각 문장을 따로 불러오기 때문에 list로 인식 => unlist를 해서 전체를 하나의 문장으로 인식하게 만듬! 
str_replace_all(unlist(jane2[grep("N", jane2)]),'/.*','')
janet <- table(str_replace_all(unlist(jane2[grep("N", jane2)]),'/.*','')) ; janet



# Wordcloud
install.packages("wordcloud")
library(wordcloud)
library(RColorBrewer) ### 글자 색깔 표현

pal <- brewer.pal(8,"Dark2") ### Dark2 색상 목록에서 8개의 색상 추출
set.seed(1234) ### 난수 고정(wordcloud()는 항상 매번 다른 모양의 워드 클라우드를 만듬 => 동일한 워드 클라우드가 생성되도록 고정!)

## 워드 클라우드 만들기
wordcloud(words = rownames(janet),
          freq = janet,
          min.freq = 3,
          max.words = 390,
          random.order = F,
          rot.per = .1,
          scale = c(5,.5),
          colors = pal)
'''
names: 출력할 단어들
freq: 빈도 수
scale: 글자의 크기 c(큰값, 작은값)
min.freq: 최소 빈도 수를 지정
max.words: 이 값 이상의 빈도 수면 삭제
random.order: 출력되는 순서를 임의로 지정 
rot.per: 단어 배치
colors: 출력될 단어들의 색상 
'''

daily <- readLines("C://data/daily.txt")
daily2 <- SimplePos09(daily) 
unlist(daily2[grep("N", daily2)]) ### 각 문장을 따로 불러오기 때문에 list로 인식 => unlist를 해서 전체를 하나의 문장으로 인식하게 만듬! 
str_replace_all(unlist(daily2[grep("N", daily2)]),'/.*','')
dailyt <- table(str_replace_all(unlist(daily2[grep("N", daily2)]),'/.*','')) ; dailyt

pal <- brewer.pal(10,"Dark2") ### Dark2 색상 목록에서 8개의 색상 추출
set.seed(1234) ### 난수 고정(wordcloud()는 항상 매번 다른 모양의 워드 클라우드를 만듬 => 동일한 워드 클라우드가 생성되도록 고정!)

## 워드 클라우드 만들기
wordcloud(words = rownames(dailyt),
          freq = dailyt,
          min.freq = 1,
          max.words = 390,
          random.order = F,
          rot.per = .1,
          scale = c(5,.5),
          colors = pal)

## wordcloud2 
install.packages("wordcloud2")
library(devtools)
devtools::install_github("lchiffon/wordcloud2")
library(wordcloud2)

wordcloud2(dailyt, shape="pentagon")
wordcloud2(dailyt, shape="star")

## brewer.pal(팔레트의 색의 수, 팔레트 이름)
library(RColorBrewer)
display.brewer.all() ### 색상 확인 가능 => brewer.pal()에 이용! 
display.brewer.pal(8,"Pastel1") ### 개별 팔레트의 색상 확인 
pie(slices, labels = lbls, main="Pie Chart of Countries")
pie(slices, labels = lbls, main="Pie Chart of Countries", col=c("white", "lightblue", "mistyrose", "lightcyan", 
                                                                "lavender", "cornsilk"))


pie


##################################################################################################
##################################################################################################
##################################################################################################





# 08/20/2018

# Web Scrapping

# 중앙일보에서 빅데이터와 관련된 기사 검색 
## https://joongang.joins.com/ <- Internet Explorer 이용 

# 빅데이터 검색 -> 중앙일보 더 보기 -> 페이징 처리 되어 있음(주소창 확인)
## https://search.joins.com/JoongangNews?page=4&Keyword=%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0&SortType=New&SearchCategoryType=JoongangNews
## Page Number(page=4)와 함께 ASCII 처리 되어 있음 
## 일일히 복사해서 붙여넣기 하면 귀찮음! 
## 자동으로 긁어오게 해야 함! (웹페이지에 대한 소스 이용)

## 마우스 오른쪽 클릭 -> 요소 검사(F12)
## 왼쪽 상단 3개의 버튼 중 포인터 모양 클릭 -> 분석하고 싶은 기사 제목 클릭 -> 해당 기사에 대한 소스 확인 가능 
## 실제 분석해야 할 데이터는 기사 제목이 아니라, 그 안에 있는 내용! 
## <a href="https://news.joins.com/article/22896642" target="_blank">'폭염'도 견디는 에너지 자립도시 만든다...전기도 알아서 생산</a>
### (a라는 태그 안의 href) 
## 위의 소스를 더블 클릭 -> 주소 복사해서 새 탭에서 열기 

## 위의 주소를 변수에 담아, 변수에 있는 URL을 하나씩 수행 + 텍스트 긁어옴 + 정제 작업 

install.packages("rvest")
library(rvest)

## 키워드(빅데이터) 검색했을 때 나온 URL Copy & Paste
### https://search.joins.com/joongangnews?keyword=%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0&searchcategorytype=JoongangNews
### 2번째 페이지 갔다가 1번째 페이지로 다시 넘어오면 URL이 바뀜!(Page Number 추가) <- https://search.joins.com/JoongangNews?page=1&Keyword=%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0&SortType=New&SearchCategoryType=JoongangNews

## 페이지 넘기게 되면, URL의 나머지 부분은 다 똑같고, "page=1" 이 부분만 달라짐 
## -> for문 이용! 

# read_html() <- 내가 긁어와야 할 URL 입력! 
html <- read_html("https://search.joins.com/JoongangNews?page=1&Keyword=%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0&SortType=New&SearchCategoryType=JoongangNews")
html ### 실제 주소 부분만 찾아서 어떤 변수에 넣어줌 
str(html)
## 각 기사의 소스를 보면, 내용은 바뀌는데, 바뀌지 않는 tag가 있음! 
## 오른쪽의 "인라인 스타일" 확인 -> .list_default .headline a

# html_nodes(소스, 태그) 
## 브라우저마다 소스가 달라서, 코드 작성할 때 주의할 것! 
url <- html_nodes(html, ".list_default .headline") %>% ### 여러 개의 태그!(".list_default", ".headline")
  html_nodes("a") %>% ### a 태그
  html_attr("href") ### href 
url ### 내가 긁어와야 할 기사들 주소 확인 가능! 

## 이제 기사에서 그림을 제외한 텍스트 긁어와야 함! 
## 해당 기사에서 기사 본문을 요소 선택하면, 하단에 어느 태그에 속해있는지 쉽게 확인 가능! 
## -> div#article_body 부분까지 긁어오면 됨! (그게 본문 부분에 해당)

## https://news.joins.com/article/22896642 
### 위의 주소가 위의 url 변수 안에 들어 있는 주소 -> loop문 돌려서 div#article_body 부분만 캡쳐하면 됨! 

html <- read_html("https://news.joins.com/article/22896642")
html ### 이 안에 #article_body 찾으면 됨! 

# html_nodes(소스, "#article_body")
txt <- html_nodes(html, "#article_body") %>% 
  html_text() 
txt ### 본문 내용 확인 가능! 
str(txt)





# 10페이지까지 기사(100개의 URL)들을 긁어와서 변수 저장 후, 변수에 있는 문서들에서 어떤 단어가 가장 많이 나왔는지 확인! 

## 1. 필요한(추출해야 할) 코드 확인
data <- c()
for (i in 1:10) {
  webpage <- read_html(paste0("https://search.joins.com/JoongangNews?page=",i,"&Keyword=%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0&SortType=New&SearchCategoryType=JoongangNews"))
  data <- c(data, html_nodes(webpage, ".headline") %>% ### 태그 확인에 익숙해져야! 
              html_nodes('a') %>% 
              html_attr('href'))
}
length(data)

## 2. 텍스트 형태로 변수 저장 
txt <- c()
for (i in 1:length(data)){
  webpage <- read_html(data[i])
  temp <- html_nodes(webpage, "#article_body") %>% 
    html_text()
  txt <- c(txt,temp)
}

txt2 <- extractNoun(paste(unlist(txt),collapse = ""))
txt2 <- unlist(txt2)
txt2 <- str_split(txt2,' ') ; txt2
txt3 <- unlist(Filter(function(x){nchar(x)>=2}, txt2)) ; txt3
txt4 <- table(txt3) ; txt4

txt2 <- SimplePos09(txt) 
txt3 <- str_match(txt2, '([A-Z가-R]+/N)') 
txt4 <- str_replace_all(txt3,'/N.*','') ; txt4
txt4 <- Filter(function(x) {nchar(x) >= 2} ,txt4) ; txt4

txt5 <- table(txt4) ; txt5

pal <- brewer.pal(8,"Dark2") ### Dark2 색상 목록에서 8개의 색상 추출
set.seed(1234) ### 난수 고정(wordcloud()는 항상 매번 다른 모양의 워드 클라우드를 만듬 => 동일한 워드 클라우드가 생성되도록 고정!)

## 워드 클라우드 만들기
wordcloud(words = txt4,
          freq = txt5,
          min.freq = 1,
          max.words = 300,
          random.order = F,
          rot.per = .1,
          scale = c(5,.5),
          colors = pal)

# 태그 찾는 법
## 각 기사에 공통되는 태그 먼저 찾은 다음, 차례로 올라가기 

# Scrapping 시 주의 사항
## 조선일보 들어가 보면, 헬스조선, 조선경제i 등 사이트가 다름 -> 태그도 달라짐!(URL이 다름) -> 사이트가 다를 경우는 따로따로 작업 수행해야! 
## "조선일보"에 해당되는 뉴스 기사만 검색
## -> .search_news_box 태그로 검색 
## 조선일보는 같은 URL 밑에도 여러 개의 href가 있음! <- .search_news 태그 안에도 여러 개의 URL 존재(불필요한 scrapping)
## <- <dd class="thumb">에 해당되는 부분만 추출해야 함! 
## .search_news_box => .search_news => .thumb 

## 조선일보는 한 기사 안에 여러 URL로 분리되서 표현되어 있음 
## .news_article -> #news_body_all 

## 1. 필요한(추출해야 할) 코드 확인
data <- c()
for (i in 1:10) {
  webpage <- read_html(paste0("http://search.chosun.com/search/news.search?query=%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0&pageno=",i,"&orderby=news&naviarraystr=&kind=11000&cont1=&cont2=&cont5=&categoryname=%EC%A1%B0%EC%84%A0%EC%9D%BC%EB%B3%B4&categoryd2=&c_scope=paging&sdate=&edate=&premium="))
  data <- c(data, html_nodes(webpage, ".search_news_box .search_news .thumb") %>% 
              html_nodes('a') %>% 
              html_attr('href'))
}
length(data)
head(data)

## 2. 텍스트 형태로 변수 저장 
txt <- c()
for (i in 1:length(data)){
  webpage <- read_html(data[i])
  temp <- html_nodes(webpage, ".news_body_all #news_body_id") %>% 
    html_text()
  txt <- c(txt,temp)
}
head(txt)

txt2 <- extractNoun(txt)
txt2 <- str_split(txt2,' ') ; head(txt2)
txt2 <- str_match(txt2, '([A-Z가-R])') ; txt2
txt3 <- unlist(Filter(function(x){nchar(x)>=2}, txt2)) ; tail(txt3)
txt4 <- table(txt3) ; txt4

txt5<-c()
for (i in txt4){
  if (!i %in% c('입력','제휴','안내','구독','신청')){ 
    txt5<-c(txt2,i)
  }
}
txt5


url2 <- "http://find.mk.co.kr/new/search.php?pageNum=1&cat=&cat1=&media_eco=&pageSize=20&sub=news&dispFlag=OFF&page=news&s_kwd=%BA%F2%B5%A5%C0%CC%C5%CD&s_page=news&go_page=&ord=1&ord1=1&ord2=0&s_keyword=%BA%F2%B5%A5%C0%CC%C5%CD&s_i_keyword=%BA%F2%B5%A5%C0%CC%C5%CD&s_author=&y1=1991&m1=01&d1=01&y2=2018&m2=08&d2=20&ord=1&area=ttbd"
read_html(iconv(url2, to = "latin1"),
          encoding = "latin1")



# 한겨레
## 태그 확인할 때는, 전후로 잘 봐야함! <- <dd class="photo"> 
## 풀어져 있는 거 다 닫을 수 있는 태그를 html_nodes()의 인자로 사용! 
### search-result-section first-child -> .search-result-list -> .photo
### .article-text <- 이것만 2번째 html_nodes()에 집어 넣으면, 기사 전문을 긁어내는 것이 가능! 



# 다음 영화
## 해당 영화의 평점, 리뷰 분석 
## 리뷰 분석할 때, 해당 영화에 대해서만 할 것인가, 아님 한 유저에 대해서만 할 것인가 결정할 것! 
url3 <- "https://movie.daum.net/moviedb/grade?movieId=120166&type=netizen&page=1"
read_html(url3)
### .review_info -> .desc_review 

## 평점이 일정한 수준 이상인 것만 분석하고 싶을 경우 
### .ranking_grade -> .emph_grade
### 여기에 나오는 숫자가 5점 이상인 것들만 추려서 분석! 

## cf) 네이버 영화 -> 주소창이 안 바뀜!(page number가 안 나옴)
### 이 경우는 요소 선택해서 페이지 번호를 클릭해보면, 코드에 넘버링되어 있음! (scrapping 못 하게 숨겨놓음!) 
### 그냥 paging number가 나오는 카테고리에서 분석! 
### .list_netizen -> (tbody -> tr ->) .title 
### 처음부터 .title부터 하면 안 나올 수도 있으니, 상위 클래스인 .list_netizen부터 시작! 

## 1. 필요한(추출해야 할) 코드 확인
data <- c()
for (i in 1:10) {
  webpage <- read_html(paste0("https://movie.daum.net/moviedb/grade?movieId=120166&type=netizen&page=",i))
  data <- c(data, html_nodes(webpage, ".review_info .desc_review "))
}
length(data)
head(data)

## 2. 텍스트 형태로 변수 저장 
txt <- c()
for (i in 1:length(data)){
  webpage <- read_html(data[i])
  temp <- html_nodes(webpage, ".news_body_all #news_body_id") %>% 
    html_text()
  txt <- c(txt,temp)
}
head(txt)



## 과제(~8/22)
### Web Scrapping
### 정제 작업
### Word Cloud 





##################################################################################################
##################################################################################################
##################################################################################################





# 08/24/2018

# 말뭉치

말뭉치(corpus)는 자연언어 연구를 위해 특정한 목적을 가지고 언어의 표본을 추출한 집합

```{r}
install.packages('tm')
library(tm)
data1<-readLines('c:/data/tm_example.txt')

corp1<-Corpus(VectorSource(data1)) # documents: 5 -> 문서의 갯수 의미 (vector 크기)

```
# documents

- tm 패키지가 작업할 수 있는 특별한 형태를 의미 
일반적으로 1줄이 1개의 document가 된다.

```{r}
# corpus 내용 보는 방법

summary(corp1) 
inspect(corp1) 
corp1[[1]]

Metadata:  7 # 공백을 기준으로 덩어리를 의미
Content:  chars: 42 # 글자수 구성

corp1[[1]]$meta

#  author       : character(0)
#  datetimestamp: 2018-08-24 01:04:02
#  description  : character(0)
#  heading      : character(0)
#  id           : 1
#  language     : en
#  origin       : character(0)

corp1[[1]]$content # 문서내용을 볼 수 있다.

```
# 단어 분석 - matrix로 바꿔서 사용을 해야한다.
## tm 패키지가 분석할 수 있는 Term-Document 형식의 matrix로 변환

```{r}
tdm<-TermDocumentMatrix(corp1)
tdm
m<-as.matrix(tdm) # 한글자는 무조건 버린다.
m

```
# 한글자도 분석을 하고 싶다면 옵션을 사용한다.

```{r}
tdm<-TermDocumentMatrix(corp1,control=list(WordLengths=c(1,Inf)))

# WordLengths -> 단어 분석 갯수를 정해서 구간을 정한다.
m<-as.matrix(tdm)
m
```
# ★★  gsub 사용시  주의해야한다.  (corpus 사용시)

# tm_map : 말뭉치 정제 함수
```{r}
corp2<-tm_map(corp1,stripWhitespace)

corp2<-tm_map(corp2,tolower) # 대문자가 있을 경우 소문자로 변환

corp2<-tm_map(corp2,removeNumbers) # 숫자제거

corp2<-tm_map(corp2,removePunctuation) # 특수문자 제거

inspect(corp2) # 값 확인

```
# 말뭉치에서 gsub을 이용하고 싶다면 

```{r}

corp3<-gsub('~','',corp1) # 이건 불가능하다 

tostring<-content_transformer(function(x,from,to) gsub(from,to,x)) 

corp3<-tm_map(corp1, tostring,"~","")
corp3<-tm_map(corp3, tostring,"!","")
corp3<-tm_map(corp3, tostring,",","")

inspect(corp3)
```
# 불용어 제거(전치사, 관사 등) 

```{r}
stopwords('en') # 제거하고 싶은 용어를 여기다 추가 (en은 영어를 의미)

sword<-c('and','but','not')

corp2<-tm_map(corp2,removeWords,sword) # 내가 원하는 값만 제거하는 방법


sword<-c(stopwords('en'),'and','but','not')

inspect(corp2)
tdm2 <- TermDocumentMatrix(corp2)
m2 <- as.matrix(tdm2)
m2

freq1<-sort(rowSums(m2),decreasing=T) # 빈도수 체크
freq1

freq2<-sort(colSums(m2),decreasing=T) # 문장의 단어 수
freq2


# 특정 횟수 이상 언급된 단어들만 출력

findFreqTerms(tdm2,2) # 말뭉치 만들어 놓은 걸로도 가능하다.

```
# 특정 단어와 상관관계를 찾고 싶을 경우 

```{r}
findAssocs(tdm,"apple",0.5)

library(RColorBrewer)
library(wordcloud)
palete <- brewer.pal(7,"Set3")
wordcloud(names(freq1),freq=freq1,min.freq=1,colors=palete)

barplot(freq1,main="tm packages",las=2)

ggplot() # 표현해보기

```
# 연관있는 단어 그래프로 만들기 (관계도 그리기)
```{r}
# 행렬의 곱 사용하면 연관있는 단어를 분석하는 것이 가능하다.
mm<-m2%*%t(m2)
mm

m2
t(m2)

install.packages('igraph')
library(igraph)

g<-graph.adjacency(mm,weighted=T,mode="undirected")
plot(g)

# 자기자신 없애기

g2<-simplify(g) # 재귀 제거
plot(g2)

```





##################################################################################################
##################################################################################################
##################################################################################################





# 08/27/2018

# 히스토그램은 자료가 모여 있는 위치나 자료의 분포에 관한 대략적인 정보를 한 눈에 파악할 수 있다는 장점은 있지만, 
# 구체적인 수치 정보를 쉽게 알아 볼 수 없다는 단점이 있다. 

# 따라서 최소값, 제1사분위수, 중위수, 제3사분위수, 최대값의 다섯가지 요약 수치 등을 이용한 상자그림(boxplot)으로 나타낼 수 있다. 

boxplot(noise)
boxplot(noise, col = "red", horizontal = T) ### horizontal shape 

mean(noise)
median(noise)
var(noise)
sd(noise)
min(noise)
max(noise)

quantile(noise) ### min, 25%, median, 75%, max 확인 가능 
quantile(noise, type=2) ### 해당되는 실제 데이터 확인 가능(type = 2로 하는 게 일반적!)

summary(noise) ### 위(type = 1)와 동일

quantile(noise, type=2)["25%"] ### 1st Quantile에 해당되는 값 추출 
quantile(noise, type=2)["75%"] ### 3rd Quantile에 해당되는 값 추출 
Q3 <- quantile(noise, 0.75) 
Q1 <- quantile(noise, 0.25) 

# median <- length가 짝수냐 홀수냐에 따라 계산식이 달라짐! 



# Interquantile Range <- boxplot에서 긴 짝대기 사이의 구간(outliers 제외)
## IQR을 가지고 outliers 확인! 
## IQR = 제3사분위수 - 제1사분위수 
noise_iqr <- IQR(noise, type = 2) ### "type = 2" 꼭 넣어줘야 함! 
uf - lf ### 사분위수 범위: 45.1 ~ 76.3

fivenum(noise)
fivenum(noise)[2]-1.5*IQR(noise) 
fivenum(noise)[2]+1.5*IQR(noise)

# lower fence 
lf <- quantile(noise, type=2)[2] - 1.5*noise_iqr ### 데이터의 최저 기준(이거 미만은 outliers)
fivenum(noise)[2]-1.5*IQR(noise)

# upper fence
uf <- quantile(noise, type=2)[2] + 1.5*noise_iqr ### 데이터의 최고 기준(이거 초과는 outliers)
fivenum(noise)[2]+1.5*IQR(noise)

## Outliers 출력하는 법
noise[noise < lf]
noise[noise > uf]

## 사분위범위 내의 최소값, 최대값 출력 
min(noise[noise>=lf & noise<=uf])
max(noise[noise>=lf & noise<=uf])

install.packages("outliers")
library(outliers)
chisq.out.test(noise, variance=var(noise), opposite = FALSE)
chisq.out.test(noise, variance=var(noise), opposite = TRUE)

# boxplot에 숫자 입력 
text(x=lf,y=1.1,labels=lf,pos=3) 
text(x=uf,y=1.1,labels=uf,pos=3) 
text(x=quantile(noise, type=2)["25%"],y=1.2,labels=quantile(noise, type=2)["25%"],pos=3) 
text(x=quantile(noise, type=2)["75%"],y=1.2,labels=quantile(noise, type=2)["75%"],pos=3) 
text(x=median(noise),y=1.2,labels=median(noise),pos=3)
text(x=44,y=1,labels=44,pos=3)
text(x=77.1,y=1,labels=77.1,pos=3)
text(x=76.5,y=.95,labels=76.5,pos=3)

## 제1사분위수 출력
boxplot(noise, col = "red", horizontal = T)
text(quantile(noise,.25,type=2)+.5,1,labels=quantile(noise,.25,type=2),col="blue") ### quantile(noise,.25,type=2) <- 1사분위수 추출하는 법 외워놓을 것! 

## 중위수 출력
text(quantile(noise,.50,type=2)+.5,1,labels=quantile(noise,.50,type=2),col="blue")

## 제3사분위수 출력
text(quantile(noise,.75,type=2)+.5,1,labels=quantile(noise,.75,type=2),col="blue")

## 사분위범위 내에 최소값 출력(왼쪽 짝대기)
lf <- quantile(noise,.25,type=2) - 1.5*IQR(noise,type=2)
uf <- quantile(noise,.75,type=2) + 1.5*IQR(noise,type=2)
text(min(noise[noise>=lf & noise<=uf])+.5,1,labels=min(noise[noise>=lf & noise<=uf]),col="blue")

## 사분위범위 내에 최대값 출력(오른쪽 짝대기)
text(max(noise[noise>=lf & noise<=uf])+.5,1,labels=max(noise[noise>=lf & noise<=uf]),col="blue")

## 이상치 출력
text(noise[noise < lf], 1.03, labels = noise[noise < lf], col="red", cex=.7)
text(noise[noise > uf], 1.03, labels = noise[noise > uf], col="red", cex=.7)





# Machine Learning <- 소프트웨어 
## - 인공지능(Artificial Intelligence - 기계로 만들어진 지능)의 한 분야로서 컴퓨터가 학습할 수 있도록 하는 알고리즘과 기술을 개발하는 분야 
## - 통계, 데이터 과학, 컴퓨터 과학 
## - 분류(Classification): KNN(K-Nearest Neighbors) 알고리즘, 나이브베이즈(naive bayes), 결정트리(decision tree)
### 한계확률(apply <- margin=1(horiz sum), 2(vert sum)), 조건부확률, 결정확률
## - 패턴감지(pattern detection): 연관규칙
## - 수치예측(numeric prediction): 회귀(regression)
## - 군집화(clustering): K평균(kmeans) 군집화 
## - 신경망(neural network) -> Deep Learning(in Python)

# Learning
## - Supervised Learning(지도학습) -> Classification(분류), Regression(예측)
### "Labels"이 달려 있는 정해져 있는 데이터를 가지고 학습, training set을 가지고 학습
### ex. 이미지(개, 고양이) 가지고 학습, Spam Mail 처리, 시험 성적 예측(Labels - "합격", "불합격")
### 회귀: 시험 성적 예측
### Binary Classification: "합격", "불합격" <- 두 가지만 분류
### Multi Label Classification: A, B, C, D, F 학점 <- 여러 카테고리로 분류 

## - Unsupervised Learning(비지도학습) -> Clustering 
### Labels이 없는 데이터, 직접 데이터를 가지고 학습
### ex. 유사한 뉴스를 그룹으로 모으는 작업, 비슷한 단어들을 모으는 작업 



# KNN(K-Nearest Neighbors - 최근접이웃) 알고리즘 <- 유유상종 <- 거리 계산
## K-NN에서 K값은 
### 1. sqrt(n)
### 2. 홀수 

## 사회적인 관계를 관찰해 보면
## - 대략적으로 비슷한 사람끼리 모이는 성질 
## - 비슷한 취향의 사람끼리 모여서 동호회를 만들고
## - 비슷한 부류의 계층의 사람끼리 친분을 맺기도 한다. 
## 공간적인 관계를 관찰해 보면
## - 가구점이 모이는 상가 지역이 따로 형성이 되어 있다. 
## - 한약방이 밀집되어 있는 지역이 따로 모여 있는 경우가 많다. 

## 거리 계산(피타고라스의 정리), 유클리드 거리(Euclidean Distance) cf. 루트 제외하면 맨하탄 거리! 
### -> 그래프 상에 점들을 군집시키고, 한 점이 어느 cluster에 더 가까운 지 거리 계산! => 가장 거리가 가까운 cluster로 분류! 
### K: 개수 ex. 1-NN: 가장 가까운 1개의 점을 가지고 분류 
### cf1. 3-NN: 가장 가까운 3개의 점을 기준으로 최근접 이웃을 찾아, 거리가 가까운 점들의 빈도 수가 가장 높은 쪽으로 분류
### cf2. 100-NN: 그냥 단순히 빈도 수가 높은 cluster에 분류 => 제대로 분류가 안 됨! <- 과적합
## K값은 좌표 상 전체 점들의 수(n)의 "루트값"으로 정하는 게 일반적! <- sqrt(n)
### K가 짝수이면 분류가 어려울 수 있음 => "홀수" 단위!!

like <- read.csv("C://data/like.csv", stringsAsFactors = F, header = T)
head(like) ### 타입으로 분류(맨 오른쪽의 컬럼이 Label이 됨)
str(like)

colnames(like) <- c("talk","book","travel","school","tall","skin","muscle","label")
str(like)

test <- data.frame(talk=70, book=50, travel=30, school=70, tall=70, skin=40, muscle=50) ### test dataset(데이터프레임)
### cf. training dataset -> 위의 like 파일에서 dataset 만듬(데이터의 양이 많으면 많을 수록 좋음)

# Machine Learning 전용 package 
install.packages("class")
library(class)

train <- like[,-8] ### training dataset <- like에서 label 제외! 
group <- like[,8] ### label만 따로 뽑아놓음 

## knn(train, test, label, k=n) -> 거리 계산해서 해당되는 label을 리턴해주는 메소드
knn(train, test, group, k = 1, l = 0, prob = FALSE, use.all = TRUE) ### 1-NN
knn(train, test, group, k = 3, l = 0, prob = FALSE, use.all = TRUE) ### 3-NN
knn(train, test, group, k = 14, l = 0, prob = FALSE, use.all = TRUE) ### 14-NN <- k값을 어떻게 설정하느냐에 따라 의사결정의 결과가 달라질 수 있음 
knn(train, test, group, k = 1, l = 0, prob = TRUE, use.all = TRUE) ### 확률값까지 확인





##################################################################################################
##################################################################################################
##################################################################################################





# 08/28/2018

## 머신러닝에 가장 중요한 건 데이터!!!
## K-NN은 컴퓨터 사양이 좋아야 함

## K-NN <- 거리 계산 => k값이 가장 중요 



# 변수 표준화 
## 서로 다른 기준을 가진 확률 변수들을 상대적으로 비교할 수 있는 도구
## 평균과 표준편차를 N(0,1)로 동일화! 
## X ~ N(mean, var)
## Z ~ N(0,1)
## Z = (관측값 - 평균)/표준편차
'''
              한국      미국      일본
평균          200만원   2500달러  21만엔
표준편차      10만원    300       2.5만
              215만원   2800달러  23만엔
'''
z1 <- (215-200)/10 ; z1
z2 <- (2800-2500)/300 ; z2
z3 <- (23-21)/2.5 ; z3

# [문제185]  나이, 월수입, 상품구매여부를 갖는 데이터가 있다.
# 이 데이터를 이용해서 나이가 44 이고 월급이 400 만원인 사람이
# 상품을 구매할지 비구매할지를 knn 분류 알고리즘으로 분석하세요.

## 나이와 월수입의 "단위"를 신경써줘야 함! 
## 변수들이 동일한 수치가 아님 -> 제대로 된 비교, 분석 불가능! 

## 변수를 표준화하는 이유

## Degree of Freedom
### 3:3 미팅에서, 첫번째 두 사람이 여자 선택하고, 마지막 사람은 선택의 여지가 없음
### 3명의 사람 중에, 실질적으로 2명에게만 선택권이 있는 것 
### -> DF = n-1 = 2

## scale 메소드(이걸로 Z값 구할 수 있음!)
### scaled:center <- 평균
### scaled:scale <- 표준편차
buy <- read.csv("c:/data/buy.csv" , stringsAsFactors = F , header = T)
buy$age <- scale(buy$나이)
buy$pay <- scale(buy$월수입)

# 표준화
# 0~1에 해당하는 값만 표준화 시키고 싶을 때 
'''
             x - 최소값
표준화 = -----------------
          최대값 - 최소값
'''
range01 <- function(x){(x-min(x))/(max(x)-min(x))} ### 메소드 구현 

x <- c(1:5)
y <- seq(10,50,10)
(x-min(x))/(max(x)-min(x))
(y-min(y))/(max(y)-min(y))
?scale



# 이미 분류가 잘 되어 있는 지 검증
## 붓꽃 데이터
## SepalLength : 꽃받침의 길이
## SepalWidth  : 꽃받침의 폭
## PetalLength : 꽃잎의 길이
## PetalWidth  : 꽃잎의 너비
## 붓꽃의 종류 : Iris-setosa, Iris-versicolor, Iris-virginica
iris <- read.csv("c:/data/iris.csv" , stringsAsFactors = F , header = T)
iris
str(iris)
summary(iris)

sample_n(iris,10)

normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

iris_n <- as.data.frame(lapply(iris[1:4], normalize))

summary(iris_n)
table(iris$Name)
set.seed(1234) ### 난수 고정 <- sampling 할 때 같이 수행(이거 안 하면 매번 결과가 바뀜!)

## Training Set(67%), Test Set(33%)
### 정확하게(골고루) 잘 분류되어야! 
### 하나의 카테고리의 데이터만 sampling되면 분석 결과에 문제가 생길 수 있음!! 
### sample(n, data, replace=TRUE, percentage) <- 난수를 뽑아내는 메소드(n: 샘플 수, "replace=TRUE": 반복 여부)
iris_sample <- sample(2,nrow(iris), replace=TRUE, prob = c(0.67,0.33)) ### standardisation 하지 않았을 때 sampling 
iris_training <- iris[iris_sample == 1, 1:4]
iris_training
iris_train_label <- iris[iris_sample == 1, 5]
iris_train_label

iris_test <- iris[iris_sample == 2, 1:4]
iris_test
iris_test_label <- iris[iris_sample == 2, 5]
iris_test_label

library(class)

iris_model <- knn(iris_training,iris_test,iris_train_label, k=3)
iris_model

install.packages("gmodels")
library(gmodels)

CrossTable(x = iris_test_label, y = iris_model, prop.chisq=FALSE) ### test data(iris_model(knn), y축)와 실제 data(iris_test_label, x축)가 matching이 잘 되는 지 체크
'''
                | iris_model 
iris_test_label |     setosa | versicolor |  virginica |  Row Total | 
----------------|------------|------------|------------|------------|
setosa |         13 |          0 |          0 |         13 |              <- sentosa 13개 예측 잘 됨
|      1.000 |      0.000 |      0.000 |      0.325 | 
|      1.000 |      0.000 |      0.000 |            | 
|      0.325 |      0.000 |      0.000 |            | 
----------------|------------|------------|------------|------------|
versicolor |          0 |          9 |          1 |         10 |          <- 1개가 삑싸리 남 => 예측이 잘 안 됨! => 이거에 대해 고민해봐야 함
|      0.000 |      0.900 |      0.100 |      0.250 |                        => 개선!(Standardisation)
|      0.000 |      0.750 |      0.067 |            | 
|      0.000 |      0.225 |      0.025 |            | 
----------------|------------|------------|------------|------------|
virginica |          0 |          3 |         14 |         17 |           <- 3개 예측 잘못됨(어떤 데이터가 잘못되었는 지는 확인할 수 없음)
|      0.000 |      0.176 |      0.824 |      0.425 |                        => 3개가 맞고 14개가 틀릴 수도 있음! 
|      0.000 |      0.250 |      0.933 |            | 
|      0.000 |      0.075 |      0.350 |            | 
----------------|------------|------------|------------|------------|
Column Total |         13 |         12 |         15 |         40 | 
|      0.325 |      0.300 |      0.375 |            | 
----------------|------------|------------|------------|------------|
'''

## Standardisation 
iris_sample_n <- sample(2,nrow(iris_n), replace=TRUE,prob = c(0.67,0.33)) ### sample(2, replace=TRUE): 데이터를 랜덤하게 1,2로 찍음! 
iris_training_n <- iris_n[iris_sample_n == 1, 1:4] ### 1에 해당되는 데이터 추출 
iris_training_n
iris_train_label <- iris[iris_sample_n == 1, 5]
iris_train_label
str(iris_train_label)

iris_test_n <- iris_n[iris_sample_n == 2, 1:4] ### 2에 해당되는 데이터 추출 
iris_test_n
iris_test_label <- iris[iris_sample_n == 2, 5]
iris_test_label

iris_model_n <- knn(iris_training_n,iris_test_n,iris_train_label, k=3)
iris_model_n

CrossTable(x = iris_test_label, y = iris_model_n, prop.chisq=FALSE)

## sample()
x <- 10:20

s1 <- sample(2, length(x), replace=T, prob=c(.60,.40)) ### 6:4의 비율로 안 뽑히는 경우도 있음! 
x[s1==1]
x[s1==2]

set.seed(1234)
s2 <- sample(1:10, 6) ### 이게 더 나음! 
x[s2]
x[-s2]





##################################################################################################
##################################################################################################
##################################################################################################





# 08/29/2018

# 자료의 중심 

# 중심위치(central location)
## - 관찰된 자료들이 어디에 집중되어 있는가를 나타낸다.
## - 대표값(대표할 수 있는 값)
## - mean, median, mode

# 평균
## 산술평균(arithmetic mean)
## 기하평균(geometric mean) 

# 산술평균(mean)
## - 자료들의 무게 중심
### 전수조사(population) vs 표본조사(sample) => sampling을 통해 전체를 예측!(통계)
### population mean = mu // sample mean = xbar
## - μ(모집단 평균)
## - xbar(표본평균)

# 가중평균(weighted mean)
## - 각 항의 수치에 그 중요도에 비례하는 계수를 곱한 다음 산출한 평균 
## - 정밀도나 들어온 양이 같지 않은 물품의 평균 가격처럼 원래의 수치가 동등하지 않다고 생각되는 경우 사용 
### ex. 중간고사 기말고사 합
### ((70*기말고사)+(30*중간고사))/(70+30)

# 기하평균(Geometric mean)
## - 곱의 형태로 변화하는 자료
## - 비율의 평균계산에 많이 사용
## - 물가상승률, 인구변동률, 연평균증가율

# 조화평균(harmonic mean)
## - 속도 등과 같이 여러 단위가 결합되어 있을때 계산

# 절사평균, 절단평균(trimmed mean)
## - 자료 중에서 큰 관측값이나 작은 관측값을 각각 몇 만큼 버린 나머지 관측값들로부터 구한 평균 
## - 평균은 양쪽 끝값의 (최소, 최대) 변화에 민감
## - 최소, 최대를 제거한 후 평균 
## - 스포츠 경기에 많이 사용 
## - 2014년 국회의원 재산 공개 -> 97억 5667만원 => 500억 이상 절사한 평균 -> 18억 686만원 

# 중앙값(median)
## - 중심으로 좌우 분포 면적이 같다. (정중앙)
## - 이상치의 영향을 받지 않음 
## - 자료를 순서대로 늘어 놓고 전체 자료 갯수 중에 50% 되는 값 
### length가 홀수인지 짝수인지에 따라 다름! 

# 최빈값(mode)
## - 빈도 수가 가장 높은 값 
### 정규분포: 중앙값과 최빈값이 같음? 

# 자료의 퍼진 정도
## - 대표값을 중심으로 얼마나 자료들이 퍼져있는 지를 나타낸다. 
## - 범위(range): max - min 
## - 편차(deviation): observation - mean <- 편차의 합은 0

h <- c(168, 174, 171, 165, 177)
max(h) - min(h)
mean(h)
h-mean(h)
sum(h-mean(h))

# 분산(variance)
## - 개별 자료들이 평균에 대해 얼마만큼 떨어질지 기대하는 값(기대값 <- 평균)
### 모평균 <- n으로 나눔 // 표본평균 <- 자유도(n-1)로 나눔

# 모분산
### N: 모집단의 크기 // n: 표본집단의 크기 <- length()
sum((h - mean(h))^2) / length(h)

# 표본분산
sum((h - mean(h))^2) / (length(h) - 1)
var(h) ### 표본분산의 값으로 나옴! (Degree of Freedom 사용)

# 표준편차
sqrt(sum((h - mean(h))^2) / (length(h) - 1))
sd(h)

## mean ± sd
### 171 ± 4.74 (평균 171 기준으로 부터 4.74 만큼 떨어져 있다.)
### 데이터가 171을 기준으로, 아무리 커도 4.74를 넘지 못 하고, 아무리 작아도 4.74를 뺀 값의 미만이 아니다. 
### ex. 오차 범위





##################################################################################################
##################################################################################################
##################################################################################################





# 08/30/2018

# 표준화
## 비교해야 할 데이터의 기준이 서로 다르므로 같은 기준을 만들어서 비교

## 표준값 = (관측값 - 평균) / 표준편차

# 표준점수(t점수)
## 표준값 * 표준편차 + 평균 



# 확률(probability)
## 모집단 전체를 분석하는 게 아니라 모집단으로 부터 추출한 표본의 자료를 분석하기 때문에 모수를 추정하고 가설을 검정하기 때문에 확률이 중요하다. 
### 전체 데이터를 다 확인할 수 없기 때문에, 표본으로 추정
### ex. 어떤 공장에서 불량품이 어느 정도 나왔는지 확인 <- 사전 확률(이를 통해 이후의 불량품 제조를 예측)

# 확률의 개념
## - 경험 혹은 실험 결과로 특정한 사건이나 결과가 발생할 가능성
## - 내일 비가 올 확률? 
## - 로또가 당첨될 확률은? 
## - 한국 축구가 우승할 확률은? 

## 주사위 = {1,2,3,4,5,6} -> 1/6
### 주사위 던지기(실험)
### S(표본공간) = {1,2,3,4,5,6} -> 1/6

## 실험: 어떤 행위의 결과를 관찰하고 측정하여 그 결과에 대해 구체적인 값을 부여하는 행위 
## 표본공간: 실험 결과로 발생할 수 있는 모든 가능한 결과의 집합 
## 표본점: 한번의 실험결과 1

# 주관적인 확률
## - 내일 비가 올 확률은 어느 정도일까?
## - 홍길동이 내일 지각할 확률?

# 객관적인 확률
# 고전적 확률
## - 주사위를 던졌을 때 무조건 1/6
## - 예전부터 알려져 있는 확률
# 상대도수 확률
## - 같은 실험을 수없이 많이 반복했을 때 특정 사건이 발생할 수 있는 상대적 가능성
## - 동전을 던지는 실험을 반복적으로 무수히 실행할 경우 앞면이 나올 확률 1/2

# 확률의 종류
## 1. 한계확률(marginal probability), 주변확률 <- "상대도수"의 개념!!  
### - 아무런 조건이 없는 상태에서 A라는 사건이 발생할 확률
### - P(A)
### - 행과 열의 합을 빈도 전체 합으로 나누면 한계확률을 구할 수 있다. 
### - 10명 중에 한 명을 뽑았을 때 남자일 확률? 4/10 <- 이게 한계 확률
### - 10명 중에 한 명을 뽑았을 때 불만족일 확률? 3/10
'''
          만족      보통      불만족      행의합      한계확률
남성      2         1         1           4           4/10
여성      0         4         2           6           6/10
열의합    2         5         3           10          10/10
한계확률  2/10      5/10      3/10        10/10
'''

## 2. 결합확률(joint probability) <- For Bayesian! 
### - 2개 이상의 사건이 동시에 발생할 가능성을 나타내는 확률 
### - 사건 A와 사건 B가 동시에 발생할 확률
### - P(A∩B)
### - 10명 중에서 남성이면서 만족할 확률?
### - 10명 중에서 여성이면서 불만족할 확률?
'''
          만족  보통 불만족 행의합 한계확률
남        0.2  0.1    0.1    0.4      0.4
여        0.0  0.4    0.2    0.6      0.6
열의합    0.2  0.5    0.3     10      1.0
한계확률  0.2  0.5    0.3      1      0.1
'''

## 3. 조건부확률(conditional probability)
### - 이미 하나의 사건이 발생한 상태에서 또 다른 사건이 발생할 가능성을 나타내는 확률
### - 남성이라는 전제 조건 하에서 만족할 확률? 
'''
            P(A∩B)
P(A|B) = -------------
             P(B)
'''

0.2/0.4 ### P(만족|남성)

'''
            P(A∩B)
P(A|B) = -------------
             P(B)

P(A∩B) = P(A|B) * P(B)
       = P(B|A) * P(A) <- 교환법칙! 

P(B∩A) = P(B|A) * P(A)



확률의 덧셈 법칙
P(AUB) = P(A) + P(B) - P(A∩B)

S = {1,2,3,4,5,6}

집합
A = {1,2,3}
B = {2,3,4}

n(AUB) = 3 + 3 - 2 = 4

확률
P(AUB) = 3/6 + 3/6 - 2/6 = 4/6



배반사건(Mutually Independent)
사건 A와 사건 B가 서로 배반적일 경우의 덧셈법칙 <- 교집합 = 0

집합
A = {1,2,3}
B = {4,5,6}

n(AUB) = 3 + 3 - 0 = 6

확률
P(AUB) = 3/6 + 3/6 - 0/6 = 6/6



확률의 곱셈 법칙
- 확률의 곱셈 법칙은 조건부 확률을 이용하여 설명한다. 
- 조건부확률은 하나의 사건이 발생한 상태에서 또 다른 사건이 발생할 가능성을 나타내는 확률 <- 동시에 두 사건이 발생 

사건 A가 발생한 조건 하에서 사건 B가 발생할 조건부 확률
            P(A∩B)
P(B|A) = -------------
             P(A)



            사과      딸기      행의합      한계확률
남          4         3
여          2         1
열의합
한계확률
'''

# 조합(combination)
## 서로 다른 n개의 개체에서 k를 선택하는 경우의 수
'''
            n!
nCk = -------------
        k! (n-k)!
'''

# 순열(permutation)
## 조합 + 순서
'''
          n!
nPk = ---------
        (n-k)!
'''





##################################################################################################
##################################################################################################
##################################################################################################





# 08/31/2018

install.packages("BayesianTools")
library(BayesianTools)

# 베이지안 이론
## 사전 확률을 바탕으로 사후 확률을 예측! 
## - 주어진 사전확률 정보를 이용하여 사후확률을 예측하는 이론
## - 사건이 발생하고 난 후 사건 발생의 원인에 대한 사후 확률을 사건 발생 건에 이미 알고 있는 사전 확률(정보)을 이용하여 구하는 이론이다. 
## ex. 기상 예보, 스팸 메일 방지, 추천 영화 
'''
사전 확률 <- 이를 바탕으로 사후 확률 예측
            생산비율      생산확률            불량확률
A 공장      30%           p(A) = .3           P(불량|A) = .1
B 공장      50%           p(B) = .5           P(불량|B) = .05
C 공장      20%           p(C) = .2           P(불량|C) = .04



사후 확률 <- 이 불량품은 어느 공장에서 나온 불량품인지 추정해봐야!(사전 확률 이용)
P(A|불량)
P(B|불량)
P(C|불량)
                               P(A)*P(불량|A)
P(A|불량) = ---------------------------------------------------
              p(A)*P(불량|A) + p(B)*P(불량|B) + p(C)*P(불량|C)

P(A|불량) = P(A∩불량)/P(불량) = P(A)*P(불량|A)/P(불량) = P(A)*P(불량|A)/(p(A)*P(불량|A)+p(B)*P(불량|B)+p(C)*P(불량|C)) 
          = .3*.1/(.3*.1+.5*.05+.2*.04) = .48

P(B|불량) = P(B∩불량)/P(불량) = P(B)*P(불량|B)/P(불량) = P(B)*P(불량|B)/(p(A)*P(불량|A)+p(B)*P(불량|B)+p(C)*P(불량|C)) 
          = .5*.05/(.3*.1+.5*.05+.2*.04) = .40
P(C|불량) = P(C∩불량)/P(불량) = P(C)*P(불량|C)/P(불량) = P(C)*P(불량|C)/(p(A)*P(불량|A)+p(B)*P(불량|B)+p(C)*P(불량|C)) 
          = .2*.04/(.3*.1+.5*.05+.2*.04) = .13

=> A 공장에서 불량품이 나왔을 확률이 높다고 추정! 
'''



# Naive Bayes 메소드 
install.packages("e1071")
library(e1071)

movie <- read.csv("C://data/movie.csv", header = T)
head(movie)
str(movie)

## knn()은 모델을 만들 수 없음 -> 매번 분류해야 함! 
## e1071은 모델을 만들어서 추측, 예측하는 것이 가능!! 

## 1. naiveBayes(사전확률(분모), )
### laplace=0 추정기 <- 확률값이 0이 되는 것을 방지 
### 메소드가 알아서 분류해줌! 
model <- naiveBayes(movie[1:5], movie$장르, laplace=0) 
model

## 2. predict() <- 잘 분류되었는 지 확인
result <- predict(model, movie[1:5])
result
